データ・ジャーナリズムの手法を説明する：スプレッドシート、スクリプト、プログラミング（環境の）Jupyter notebooks
Written by: Sam Leon
データジャーナリズムの台頭により、何がジャーナリズムのソースとみなされるかについての考え方が変わりつつあります。
ソースは現在、公開されているデータセット、流出した電子メール、スキャンした文書、衛星画像、センサーデータなど、さまざまな形で提供されています。
これと並行して、これらのソースからストーリーを見つけるための新しい方法が登場しています。機械学習、テキスト分析、および本書の別の場所で検討されている他の技術のいくつかは、スクープのためにますます活用されています。
しかし、データは、厳密で客観的な真実であるかのようなオーラとは裏腹に、歪められたり、誤った表現をされたりすることがあります。
データ・ジャーナリストがデータセットの解釈を誤り、誤解を招くような記事を発表する事例には事欠きません。データ収集の時点で問題があり、より広い集団に対して一般的な推論を行うことができないこともあります。
例えば、サンプルの選び方に自己選択バイアスがかかっていることが考えられますが、これはインターネット上で世論調査や調査が行われる現代によく見られる問題です。
また、データ処理の段階でエラーが発生することもあります。データ処理やクリーニングには、ジオコーディング、名前のスペルミスの修正、カテゴリの調和、または統計的な外れ値を完全に除外することが含まれます。
この種のエラーの良い例としては、政治的信念とポルノ消費との間に相関関係があるとする広く知られた研究における、IPアドレスの不正確なジオコーディングが挙げられます。
もちろん、データ・ジャーナリストの仕事の本質である分析も（同様の事例が）あります。相関を因果関係と勘違いしたり、問題のデータセットを要約するために不適切な統計量を選択したりするなど、統計学的な誤りが（全体に）影響を及ぼす可能性があります。
データの収集、処理、分析がナラティブを変えうることを踏まえれば、データ・ジャーナリストはどのようにして、使用したソースが信頼できるものであり、結論を導き出すために行われた作業に問題はないと読者に請け合うことが出来るのでしょうか？
データ・ジャーナリストが単に第三者のデータや研究結果を報道しているだけなら、多くの大手ニュース・アウトレットが採用している伝統的な編集基準を逸脱する必要はありません。
一般的に、データを収集・分析した機関への言及で十分です。例えば、英国の平均寿命に関する最近のフィナンシャル・タイムズのチャートには、「出典：EuroStat（EU統計局）のデータに基づいてClub Vitaが計算した」（と標記されています）。
そうすれば、読者は引用した機関の信頼性を評価できます。責任あるジャーナリストは信頼できると思われる研究のみを報道しますが、第三者機関はその結論に至った方法を説明する責任が大きくなります。
学術的な文脈では、これにはピアレビューのプロセスが含まれる可能性が高く、科学的な出版物には、一定のレベルの透明性がある方法論が含まれます。
ジャーナリスティックな組織がデータ駆動型の調査を行うケースがますます一般的になってきている中、報道している（研究）結果の信頼性について読者に説明責任を負うことになります。
ジャーナリストは、さまざまな方法で自分たちの手法を説明するという課題に対応してきました。一般的なアプローチの一つは、結論に至るために用いた一般的な方法論を説明することです。
こうした説明は、できるだけ幅広い読者に理解してもらえるように、技術的ではない平易な言葉で表現されるべきです。
ガーディアンとグローバルウィットネスが、環境保護活動家の死を調査する方法を説明したアプローチが良い例でしょう。
しかし、社会生活におけるあらゆる手法がそうであるように、文章にも限界があります。最も重大な問題は、一般的に、分析の作成やデータの準備に使った正確な手順を明記していないことです。
したがって、結論を出すために記者が行った手順を正確に再現することは困難になり、場合によっては不可能になります。
言い換えれば、文章による説明は一般的に再現性のあるものではありません。上記の例では、データの取得、処理、分析のステップが比較的簡単な場合は、文章による説明でも問題はないかもしれません。
しかし、より複雑な技術が採用されている場合には、再現性のあるアプローチを採用する必要が出てきます。
再現性のあるデータ・ジャーナリズム
再現性は、広く現代の科学的方法の柱であるとみなされています。再現性は、結果を裏付けるプロセスを助け、問題のある発見や疑わしい理論を特定して対処するのに役立ちます。
原理的には、ジャーナリスティックな文脈でのデータの誤った使用や誤解を招くような使用を排除するのにも、同じメカニズムが役立ちます。
最近の学術史の中で最もよく知られている方法論的な誤りの一つが、参考になります。ハーバード大学のカーメン・ラインハートとケネス・ロゴフは2010年の論文の中で、ある国の債務が国内総生産（GDP）の90％以上に達すると、経済成長が平均的に減速する（0.1％の低下）としていました。
この数字はその後、緊縮財政を支持する政治家たちが（主張を裏付ける）弾みとして使いました。
結論から言うと、回帰はエクセルのエラーによるものでした。計算式に誤りがあったために、ラインハートとロゴフは、国の列全体の平均ではなく、20カ国のうち15カ国しか集計していませんでした。
（再計算の結果、債務がGDPの90％を超える）すべての国で（経済成長率）0.1%の「減速」が平均して2.2%の増加になりました。
このミスは、大学院生のトーマス・ハーンドンとマイケル・アッシュ教授、ロバート・ポリン教授が、ラインハートとロゴフが作業したオリジナルのスプレッドシートを確認したときに判明しました。
このことは、手法がわかりやすく書かれているだけでなく、分析に使用されたデータや技術そのものを押さえることの重要性を示しています。しかし、ラインハルト＝ロゴフのエラーは、他の何かを示唆しているのではないでしょうか。
エクセルは、データを扱うプロセスの大部分を設計上隠しています。スプレッドシートの分析を行う数式は、セルをクリックしたときにのみ表示されます。
これは、結論に到達するまでの手順を確認することを困難にしています。確かなことはわかりませんが、ラインハートとロゴフの分析作業が、ステップを明示的に宣言しなければならない言語（プログラミング言語など）で行われていたら、出版前にエラーが発見されていたのではないでしょうか。
エクセルベースのワークフローでは、結論に至るまでのステップを削除することが推奨されます。式ではなく、値が他のシートや列にコピーされることが多く、数値がどのように生成されたかをたどる唯一のルートは「元に戻す」キーしかありません。
「元に戻す」履歴は、もちろんアプリケーションを閉じたときに消去されますので、重要な方法論的情報を保存するのには適していないのです。

文芸的プログラミング環境の台頭:ニュースルームにおけるJupyter notebooksの活用
方法の透明性に対する新たなアプローチとして、いわゆる「文芸的プログラミング」環境を利用することが挙げられます。Buzzfeed、The New York Times、Correctivのような組織は、人間が読みやすいドキュメントを提供するためにこの環境を利用していますが、これは機械でも実行可能で、与えられた分析のステップを正確に再現することができます。
ドナルド・クヌースが1980年代に提唱した文芸的プログラミングはコンピュータコードを書くためのアプローチであり、コードの間に通常の人間の言語を挿入して、手順を説明します。
今日使用されている二つの主要な文芸的プログラミング環境は、Jupyter NotebooksとR Markdownです。
ともに、HTMLでレンダリングしてウェブ上で公開することができる単一のドキュメントに、平易な英語、ビジュアライゼーション、コードをミックスした、人間が読みやすいドキュメントを作成します。
元のデータは明示的にリンクすることができ、サードパーティのライブラリなど、その他の技術的な依存関係も明確に識別されます。
人間が読みやすい説明を重視しているだけでなく、人間の論理を反映するようにコードが順序立てられています。したがって、このパラダイムに基づき書かれたドキュメント文書は、議論の一連のステップや、調査の一連の質問に対する回答のように読むことができます。
「文芸的プログラミングの実践者は、いわばエッセイストであり、説明と優れた文体を第一に考えます。彼らは作家のように、シソーラスを片手に、変数の名前を慎重に選び、それぞれの変数の意味合いを説明しようとします。
書き手は、分かりやすいプログラムにしようと努力します。なぜなら、（文芸的プログラミングの）概念は形式的な方法と非形式的な方法を互いに補強するように組み合わせ、人間が最も理解しやすい順序になるよう（プログラムを）導入することだからです。


A good example of the form is found in Buzzfeed News’ Jupyter Notebook detailing how they analysed trends in California’s wildfires.8 Whilst the notebook contains all the code and links to source data required to reproduce the analysis, the thrust of the document is a narrative or conversation with the source data. Explanations are set out under headings that follow a logical line of enquiry. Visualisations and charts are used to bring out key themes.

One aspect of the “literate” approach to programming is that the documents produced (as Jupyter Notebook or R Markdown files) may be capable of re-assuring even those readers who cannot read the code itself that the steps taken to produce the conclusions are sound. The idea is similar to Steven Shapin and Simon Schaffer’s account of “virtual witnessing” as a means of establishing matters of fact in early modern science. Using Robert Boyle’s experimental programme as an example Shapin and Schaffer set out the role that “virtual witnessing” had:

“The technology of virtual witnessing involves the production in a reader's mind of such an image of an experimental scene as obviates the necessity for either direct witness or replication. Through virtual witnessing the multiplication of witnesses could be, in principle, unlimited. It was therefore the most powerful technology for constituting matters of fact. The validation of experiments, and the crediting of their outcomes as matters of fact, necessarily entailed their realization in the laboratory of the mind and the mind's eye. What was required was a technology of trust and assurance that the things had been done and done in the way claimed.”9.

Documents produced by literate programming environments such as as Jupyter Notebooks - when published alongside articles - may have a similar effect in that they enable the non-programming reader to visualise the steps taken to produce the findings in a particular story. While the non-programming reader may not be able to understand or run the code itself, comments and explanations in the document may be capable of re-assuring them that appropriate steps were taken to mitigate error.

Take for instance a recent Buzzfeed News story on children’s home inspections in the UK.10 The Jupyter Notebook has specific steps to check that data has been correctly filtered (Figure 1) providing a backstop against the types of simple but serious mistakes that caught Reinhart and Rogoff out. While the exact content of the code may not be comprehensible to the non-technical reader, the presence of these tests and backstops against error with appropriate plain English explanations may go some way to showing that the steps taken to produce the journalist’s findings were sound.

Figure 1: A cell from the Buzzfeed Jupyter notebook with a human readable explanation or comment explaining that its purpose is to check that the filtering of the raw data was performed correctly
Figure 1: A cell from the Buzzfeed Jupyter notebook with a human readable explanation or comment explaining that its purpose is to check that the filtering of the raw data was performed correctly
More than just reproducibility
Using literate programming environments for data stories does not just help make them more reproducible.

Publishing code can aid collaboration between organisations. In 2016, Global Witness published a web scraper that extracted details on companies and their shareholders from the Papua New Guinea company register.11 The initial piece of research aimed to identify the key beneficiaries of the corruption-prone trade in tropical timber which is having a devastating impact on local communities. While Global Witness had no immediate plans to re-use the scraper it developed, the underlying code was published on Github – the popular code sharing website.

Not long after, a community advocacy organisation, ACT NOW!, downloaded the code from the scraper, improved it and incorporated it into a their iPNG project that lets members of the public cross-check names of company shareholders and directors against other public interest sources.12 The scraper is now part of the core data infrastructure of the site, retrieving data from the Papua New Guinea company registry twice a year.

Writing code within a literate programming environment can also help to streamline certain internal processes where others within an organisation need to understand and check an analysis prior to publication. At Global Witness, Jupyter Notebooks have been used to streamline the legal review process. As notebooks set out the steps taken to a get a certain finding in a logical order, lawyers can then make a more accurate assessment of the legal risks associated with a particular allegation.

In the context of investigative journalism, one area where this can be particularly important is where assumptions are made around the identity of specific individuals referenced in a dataset. As part of our recent work on the state of corporate transparency in the UK, we wanted to establish which individuals controlled a very large number of companies. This is indicative (although not proof) of them being a so-called “nominee” which in certain contexts - such as when the individual is listed as Person of Significant Control (PSC) - is illegal. When publishing the list of names of those individuals who controlled the most companies, the legal team wanted to know how we knew a specific individual, let’s say John Barry Smith, was the same as another individual named John B. Smith.13 A Jupyter Notebook was able to clearly capture how we had performed this type of deduplication by presenting a table at the relevant step that set out the features that were used to assert the identity of individuals (see below).14 These same processes have been used at Global Witness for fact checking purposes as well.

Figure 2: A section of the Global Witness Jupyter notebook which constructs a table of individuals and accompanying counts based on them having the same first name, surname, month and year of birth and postcode.
Figure 2: A section of the Global Witness Jupyter notebook which constructs a table of individuals and accompanying counts based on them having the same first name, surname, month and year of birth and postcode.
Jupyter Notebooks have also proven particularly useful at Global Witness when there is need to monitor a specific dataset over time. For instance, in 2018 Global Witness wanted to establish how the corruption risk in the London property market had changed over a two year period.15 They acquired a new snapshot of from the land registry of properties owned by foreign companies and re-used and published a notebook we had developed for the same purpose two years previously (Figure 2).16 This yielded comparable results with minimal overhead. The notebook has an additional advantage in this context too: it allowed Global Witness to show its methodology in the absence of being able to re-publish the underlying source data which, at the time of analysis, had certain licensing restrictions. This is something very difficult to do in a spreadsheet-based workflow. Of course, the most effective way of accounting for your method will always be to publish the raw data used. However, journalists often use data that cannot be re-published for reasons of copyright, privacy or source protection.

While literate programming environments can clearly enhance the accountability and reproducibility of a journalist’s data work, alongside other benefits, there are some important limitations.

One such limitation is that to re-produce (rather than just follow or “virtually witness”) an approach set out in a Jupyter Notebook or R Markdown document you need to know how to write, or at least run, code. The relatively nascent state of data journalism means that there is still a fairly small group of journalists, let alone general consumers of journalism, who can code. This means that it is unlikely that the Github repositories of newspapers will receive the same level of scrutiny as say peer reviewed code referenced in an academic journal where larger portions of the community can actually interrogate the code itself. Data journalism may therefore be more prone to hidden errors in code itself when compared to research with a more technically literate audience. As Jeff Harris points out, it probably won’t be long before we see programming corrections published by media outlets in much the same way as traditional that factual errors are published.17 It is worth noting in this context that tools like Workbench (which is also mentioned in Jonathan Stray’s chapter in this book) are starting to be developed for journalists, which promise to deliver some of the functionality of literate programming environments without the need to write or understand any code18.

At this point it is also worth considering whether the new mechanisms for accountability in journalism may not just be new means through which a pre-existing “public” can scrutinise methods, but indeed play a role in the formation of new types of “publics”. This is a point made by Andrew Barry in his essay, Transparency as a political device:

“Transparency implies not just the publication of specific information; it also implies the formation of a society that is in a position to recognize and assess the value of – and if necessary to modify – the information that is made public. The operation of transparency is addressed to local witnesses, yet these witnesses are expected to be properly assembled, and their presence validated. There is thus a circular relation between the constitution of political assemblies and accounts of the oil economy – one brings the other into being. Transparency is not just intended to make information public, but to form a public which is interested in being informed”19

The methods elaborated on above for accounting for data journalistic working in themselves may play a role in the emergence of new groups of more technically aware publics that wish to scrutinise and hold reporters to account in ways not previously possible before the advent and use of technologies like literate programming environments in the journalistic context.

This idea speaks to some of Global Witness’s work on data literacy in order to enhance the accountability of the extractives sector. Landmark legislation in the European Union that forces extractives companies to publish project-level payments to governments for oil, gas and mining projects, an area highly vulnerable to corruption, has opened the possibility for far greater scrutiny of where these revenues actually accumulate. However, Global Witness, and other advocacy groups within the Publish What You Pay coalition have long observed that there is no pre-existing “public” which could immediately play this role. As a result, Global Witness and others have developed resources and training programmes to assemble journalists and civil society groups in resource rich countries who can be supported in developing the skills to use this data to more readily hold companies to accounts. One component to this effort has been the development and publication of specific methodologies for red flagging suspicious payment reports that could be corrupt.20

Literate programming environments are currently a promising means through which data journalists are making their methodologies more transparent and accountable. While data will always remain open to multiple interpretations, technologies that make a reporter’s assumptions explicit and their methods reproducible are valuable. They aid collaboration and open up an increasingly technical discipline to scrutiny from various publics. Given the current crisis of trust in journalism, a wider embrace of reproducible approaches may be one important way in which data teams can maintain their credibility.

Works Cited

Jacob Harris, ‘Distrust Your Data’, Source, 22 May 2014.

Ben Leather and Billy Kyte, ‘Defenders: Methodology’, Global Witness, 13 July 2017.

Donald Knuth, ‘Literate Programming’, Computer Science Department, Stanford University, Stanford, CA 94305, USA, 1984.

Andrew Barry, ‘Transparency as a political device In: Débordements: Mélanges offerts à Michel Callon’, Paris: Presses des Mines, 2010.

Carmen M. Reinhart and Kenneth S. Rogoff, ‘Growth in a Time of Debt’, The National Bureau of Economic Research, December 2011.

Donald E. Knuth, ‘Literate Programming’, Stanford, California: Center for the Study of Language and Information, 1992.

Steven Shapin and Simon Schaffer, ‘Leviathan and the Air-Pump: Hobbes, Boyle and the Experimental Life’, Princeton University Press, 1985.

Richard Holmes and Jeremy Singer-Vine, ‘Danger and Despair Inside Cambian Group, Britain’s Largest Private Child Care Home Provider’, BuzzFeed News, 26 July 2018.

Naomi Hirst and Sam Leon, ‘Two Years On, We’re Still in the Dark About the UK’s 86,000 Anonymously Owned Homes’, Global Witness, 7 December 2017.

Jacob Harris, ‘The Times Regrets the Programmer Error’, Source, 19 September 2013.

Global Witness, ‘Finding the Missing Millions’, 9 August 2018.

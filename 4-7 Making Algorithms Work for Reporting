報道にアルゴリズムを活用する
Written by Jonathan Stray

概要

洗練されたデータ分析アルゴリズムは、調査報道に大いに役立ちますが、その作業のほとんどはデータの取得とクリーニングです。

キーワード：アルゴリズム、機械学習、コンピュテーショナル・ジャーナリズム、データ・ジャーナリズム、調査報道、データ・クリーニング
コンピュテーショナル・ジャーナリズムの外聞をはばかる秘密は、ストーリーの「アルゴリズム」は、すべての時間と労力を投じる部分ではないということです。
誤解しないで。洗練されたアルゴリズムは、報道、特に調査報道において非常に有効です。機械学習（コンピュータにパターンを発見させる技術）は、膨大なデータの中から重要な文書を見つけ出すのに使われています。
また、自然言語処理（言語を理解するためのトレーニング）により、文書から人名や企業名を抽出することができ、記者は誰がストーリーに関わっているかを理解するための近道となります。
さらに、記者は不正や偏見を発見するために、さまざまな統計的分析を行っています。
しかし、アルゴリズムを実行するのは簡単です。データを入手し、それをクリーニングし、アルゴリズムのリードをフォローすることこそ大変なのです。
これを説明するために、調査報道における機械学習の成功例として、The Atlanta Journal-Constitutionの医師による性的虐待に関する驚くべき記事「License to Betray」を取り上げましょう（Teegardin et al,2016)。
記者たちは、米国の全州の10万件以上の医師の懲戒記録を分析し、患者に性的虐待を加えた医師が診療を続けることを許可されていたケースを2400件発見しました。
すべての報告書を読むのではなく、機械学習を応用して、性的虐待に関わる可能性の高い報告書を見つけることで、この山を大幅に減らしました。
その結果、10回以上ふるいにかけてたった6,000個の文書にまで減らすことができ、それを手作業で読み、見直すことができたのです。
記者のジェフ・エルンストハウゼンによると、機械学習がなければ全国的な記事にはならなかったといいます。「もしかしたら、地域限定の記事にしていた可能性もあるかもしれない」と後に語っています（Diakopoulos, 2019）。
これは、ジャーナリズムにおけるアルゴリズムの比類なき成功例であり、この手法はもっと広く利用できるでしょう。
機械学習自体は難しいことではありません。エルンストハウゼンが使用した「ロジスティック回帰」という手法は、どの単語が含まれているかによって文書を分類する標準的な統計的アプローチです。
数十行のPythonで実装することができ、オンラインには多くのチュートリアルがあります。
ほとんどのストーリーでは、作業の大半がセットアップとその結果を利用することを占めます。データのスクレイピング、クリーニング、フォーマット、ロード、チェック、修正などの作業を際限なく続けなければなりません。
アルゴリズム分析の結果は、多くの場合、手がかりやヒントに過ぎず、分析ツールではなくコラボレーションツールを必要とする記者チームによる大量の手作業による取材を経て、初めて記事になります。
このような作業は、データの仕事の中でも特に地味なものなので、あまり教えられませんし、話題にもなりません。しかし、データドリブンな記事を書くためには、この準備とフォローアップにほとんどの時間と労力を費やすことになります。

For “License to Betray,” just getting the data was a huge challenge. There is no national database of doctor disciplinary reports, just a series of state-level databases. Many of these databases do not contain a field indicating why a doctor was disciplined. Where there is a f ield, it often doesn’t reliably code for sexual abuse. At first, the team tried to get the reports through freedom of information requests. This proved to be prohibitively expensive, with some states asking for thousands of dollars to provide the data. So, the team turned to scraping documents from state medical board websites (Ernsthausen, 2017). These documents had to be OCR’d (turned into text) and loaded into a custom web-based application for collaborative tagging and review.

Then the reporters had to manually tag several hundred documents to produce training data. After machine learning ranked the remaining 100,000, it took several more months to manually read the 6,000 docu- ments that were predicted to be about sex abuse, plus thousands of other documents containing manually picked key words. And then, of course, there was the rest of the reporting, such as the investigation of hundreds of specific cases to flesh out the story. This relied on other sources, such as previous news stories and, of course, personal interviews with the people involved.

The use of an algorithm—machine learning—was a key, critical part of the investigation. But it was only a tiny amount of the time and effort spent. Surveys of data scientists consistently show that most of their work is data “wrangling” and cleaning—often up to 80%—and journalism is no different (Lohr, 2014).

Algorithms are often seen as a sort of magic ingredient. They may seem complex or opaque, yet they are unarguably powerful. This magic is a lot more fun to talk about than the mundane work of preparing data or following up a long list of leads. Technologists like to hype their technology, not the equally essential work that happens around it, and this bias for new and sophisticated tools sometimes carries over into journalism. We should teach and exploit technological advances, certainly, but our primary responsibility is to get journalism done, and that means grappling with the rest of the data pipeline, too.

In general, we underappreciate the tools used for data preparation. OpenRefine is a long-standing hero for all sorts of cleaning tasks. Dedupe. io is machine learning applied to the problem of merging near-duplicate names in a database. Classic text-wrangling methods like regular expressions should be a part of every data journalist’s education. In this vein, my current project, Workbench, is focused on the time-consuming but mostly invisible work of preparing data for reporting—everything that happens before the “algorithm.” It thus aims to make the whole process more collaborative, so reporters can work together on large data projects and learn from each other’s work, including with machines.

Algorithms are important to reporting, but to make them work, we have to talk about all of the other parts of data-driven journalism. We need to enable the whole workflow, not just the especially glamorous, high-tech parts.

Works cited

Diakopoulos, N. (2019). Automating the news: How algorithms are rewriting the media. Harvard University Press.

Ernsthausen, J. (2017). Doctors and sex abuse. NICAR 2017, Jacksonville. docs.google.com/presentation/d/1keGeDk_wpBPQgUOOhbRarPPFbyCculTObGLeAhOMmEM/edit#slide=id.p

Lohr, S. (2014, August 17). For big-data scientists, “janitor work” is key hurdle to insights. The New York Times. www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html

Teegardin, C., Robbins, D., Ernsthausen, J., & Hart, A. (2016, July 5). License to betray. The Atlanta Journal-Constitution, Doctors & Sex Abuse. doctors.ajc.com/doctors_sex_abuse

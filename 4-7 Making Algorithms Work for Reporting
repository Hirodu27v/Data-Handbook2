報道にアルゴリズムを活用する
Written by Jonathan Stray

概要

洗練されたデータ分析アルゴリズムは、調査報道に大いに役立ちますが、その作業のほとんどはデータの取得とクリーニングです。

キーワード：アルゴリズム、機械学習、コンピュテーショナル・ジャーナリズム、データ・ジャーナリズム、調査報道、データ・クリーニング
コンピュテーショナル・ジャーナリズムの外聞をはばかる秘密は、ストーリーの「アルゴリズム」は、すべての時間と労力を投じる部分ではないということです。
誤解しないで。洗練されたアルゴリズムは、報道、特に調査報道において非常に有効です。機械学習（コンピュータにパターンを発見させる技術）は、膨大なデータの中から重要な文書を見つけ出すのに使われています。
また、自然言語処理（言語を理解するためのトレーニング）により、文書から人名や企業名を抽出することができ、記者は誰がストーリーに関わっているかを理解するための近道となります。
さらに、記者は不正や偏見を発見するために、さまざまな統計的分析を行っています。
しかし、アルゴリズムを実行するのは簡単です。データを入手し、それをクリーニングし、アルゴリズムのリードをフォローすることこそ大変なのです。
これを説明するために、調査報道における機械学習の成功例として、The Atlanta Journal-Constitutionの医師による性的虐待に関する驚くべき記事「License to Betray」を取り上げましょう（Teegardin et al,2016)。
記者たちは、米国の全州の10万件以上の医師の懲戒記録を分析し、患者に性的虐待を加えた医師が診療を続けることを許可されていたケースを2400件発見しました。
すべての報告書を読むのではなく、機械学習を応用して、性的虐待に関わる可能性の高い報告書を見つけることで、この山を大幅に減らしました。
その結果、10回以上ふるいにかけてたった6,000個の文書にまで減らすことができ、それを手作業で読み、見直すことができたのです。
記者のジェフ・エルンストハウゼンによると、機械学習がなければ全国的な記事にはならなかったといいます。「もしかしたら、地域限定の記事にしていた可能性もあるかもしれない」と後に語っています（Diakopoulos, 2019）。
これは、ジャーナリズムにおけるアルゴリズムの比類なき成功例であり、この手法はもっと広く利用できるでしょう。
機械学習自体は難しいことではありません。エルンストハウゼンが使用した「ロジスティック回帰」という手法は、どの単語が含まれているかによって文書を分類する標準的な統計的アプローチです。
数十行のPythonで実装することができ、オンラインには多くのチュートリアルがあります。
ほとんどのストーリーでは、作業の大半がセットアップとその結果を利用することを占めます。データのスクレイピング、クリーニング、フォーマット、ロード、チェック、修正などの作業を際限なく続けなければなりません。
アルゴリズム分析の結果は、多くの場合、手がかりやヒントに過ぎず、分析ツールではなくコラボレーションツールを必要とする記者チームによる大量の手作業による取材を経て、初めて記事になります。
このような作業は、データの仕事の中でも特に地味なものなので、あまり教えられませんし、話題にもなりません。しかし、データドリブンな記事を書くためには、この準備とフォローアップにほとんどの時間と労力を費やすことになります。
『License to Betray』では、データを入手するだけでも大変な苦労がありました。医師の懲戒に関する全国的なデータベースは存在せず、州レベルのデータベースがいくつかあるだけです。
これらのデータベースの多くには、医師が懲戒処分を受けた理由を示す項目がありません。記入欄があっても、性的虐待が確実にコード化されていないことが多いのです。
チームはまず、情報公開請求で報告書を入手しようとしました。しかし、州によっては数千ドルを要求してくるところもあり、法外に高価なものとなりました。
そこでチームは、州の医療委員会のウェブサイトから文書をスクレイピングすることにしました（Ernsthausen, 2017）。
これらの文書はOCR（テキスト化）され、共同でタグ付けやレビューを行うためのカスタムWebベースのアプリケーションに読み込む必要がありました。
学習データを作成するために、数百の文書に手作業でタグ付けをしなければなりませんでした。機械学習で残りの10万件をランク付けした後、性的虐待について予測された6,000件の文書と、手作業で選んだキーワードを含む数千件の文書を読むのにさらに数カ月を要しました。
さらに、ストーリーを具体化するために、何百もの具体的な事件を調査するなど、その他の取材も必要でした。
過去のニュース記事や、関係者への個人的なインタビューなど、他の情報源も利用しました。

The use of an algorithm—machine learning—was a key, critical part of the investigation. But it was only a tiny amount of the time and effort spent. Surveys of data scientists consistently show that most of their work is data “wrangling” and cleaning—often up to 80%—and journalism is no different (Lohr, 2014).

Algorithms are often seen as a sort of magic ingredient. They may seem complex or opaque, yet they are unarguably powerful. This magic is a lot more fun to talk about than the mundane work of preparing data or following up a long list of leads. Technologists like to hype their technology, not the equally essential work that happens around it, and this bias for new and sophisticated tools sometimes carries over into journalism. We should teach and exploit technological advances, certainly, but our primary responsibility is to get journalism done, and that means grappling with the rest of the data pipeline, too.

In general, we underappreciate the tools used for data preparation. OpenRefine is a long-standing hero for all sorts of cleaning tasks. Dedupe. io is machine learning applied to the problem of merging near-duplicate names in a database. Classic text-wrangling methods like regular expressions should be a part of every data journalist’s education. In this vein, my current project, Workbench, is focused on the time-consuming but mostly invisible work of preparing data for reporting—everything that happens before the “algorithm.” It thus aims to make the whole process more collaborative, so reporters can work together on large data projects and learn from each other’s work, including with machines.

Algorithms are important to reporting, but to make them work, we have to talk about all of the other parts of data-driven journalism. We need to enable the whole workflow, not just the especially glamorous, high-tech parts.

Works cited

Diakopoulos, N. (2019). Automating the news: How algorithms are rewriting the media. Harvard University Press.

Ernsthausen, J. (2017). Doctors and sex abuse. NICAR 2017, Jacksonville. docs.google.com/presentation/d/1keGeDk_wpBPQgUOOhbRarPPFbyCculTObGLeAhOMmEM/edit#slide=id.p

Lohr, S. (2014, August 17). For big-data scientists, “janitor work” is key hurdle to insights. The New York Times. www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html

Teegardin, C., Robbins, D., Ernsthausen, J., & Hart, A. (2016, July 5). License to betray. The Atlanta Journal-Constitution, Doctors & Sex Abuse. doctors.ajc.com/doctors_sex_abuse

報道にアルゴリズムを活用する
Written by Jonathan Stray

概要

洗練されたデータ分析アルゴリズムは、調査報道に大いに役立ちますが、その作業のほとんどはデータの取得とクリーニングです。

キーワード：アルゴリズム、機械学習、計算論的ジャーナリズム、データ・ジャーナリズム、調査報道、データ・クリーニング
コンピュテーショナル・ジャーナリズムの外聞をはばかる秘密は、ストーリーの「アルゴリズム」は、すべての時間と労力を投じる部分ではないということです。
誤解しないで。洗練されたアルゴリズムは、報道、特に調査報道において非常に有効です。機械学習（コンピュータにパターンを発見させる技術）は、膨大なデータの中から重要な文書を見つけ出すのに使われています。
また、自然言語処理（言語を理解するためのトレーニング）により、文書から人名や企業名を抽出することができ、記者は誰がストーリーに関わっているかを理解するための近道となります。
さらに、記者は不正や偏見を発見するために、さまざまな統計的分析を行っています。
しかし、アルゴリズムを実行するのは簡単です。データを入手し、それをクリーニングし、アルゴリズムのリードをフォローすることこそ大変なのです。
これを説明するために、調査報道における機械学習の成功例として、The Atlanta Journal-Constitutionの医師による性的虐待に関する驚くべき記事「License to Betray」を取り上げましょう（Teegardin et al,2016)。
記者たちは、米国の全州の10万件以上の医師の懲戒記録を分析し、患者に性的虐待を加えた医師が診療を続けることを許可されていたケースを2400件発見しました。
すべての報告書を読むのではなく、機械学習を応用して、性的虐待に関わる可能性の高い報告書を見つけることで、この山を大幅に減らしました。
その結果、10回以上ふるいにかけてたった6,000個の文書にまで減らすことができ、それを手作業で読み、見直すことができたのです。
記者のジェフ・エルンストハウゼンによると、機械学習がなければ全国的な記事にはならなかったといいます。「もしかしたら、地域限定の記事にしていた可能性もあるかもしれない」と後に語っています（Diakopoulos, 2019）。
これは、ジャーナリズムにおけるアルゴリズムの比類なき成功例であり、この手法はもっと広く利用できるでしょう。
機械学習自体は難しいことではありません。エルンストハウゼンが使用した「ロジスティック回帰」という手法は、どの単語が含まれているかによって文書を分類する標準的な統計的アプローチです。
数十行のPythonで実装することができ、オンラインには多くのチュートリアルがあります。
ほとんどのストーリーでは、作業の大半がセットアップとその結果を利用することを占めます。データのスクレイピング、クリーニング、フォーマット、ロード、チェック、修正などの作業を際限なく続けなければなりません。
アルゴリズム分析の結果は、多くの場合、手がかりやヒントに過ぎず、分析ツールではなくコラボレーションツールを必要とする記者チームによる大量の手作業による取材を経て、初めて記事になります。
このような作業は、データの仕事の中でも特に地味なものなので、あまり教えられませんし、話題にもなりません。しかし、データドリブンな記事を書くためには、この準備とフォローアップにほとんどの時間と労力を費やすことになります。
『License to Betray』では、データを入手するだけでも大変な苦労がありました。医師の懲戒に関する全国的なデータベースは存在せず、州レベルのデータベースがいくつかあるだけです。
これらのデータベースの多くには、医師が懲戒処分を受けた理由を示す項目がありません。記入欄があっても、性的虐待が確実にコード化されていないことが多いのです。
チームはまず、情報公開請求で報告書を入手しようとしました。しかし、州によっては数千ドルを要求してくるところもあり、法外に高価なものとなりました。
そこでチームは、州の医療委員会のウェブサイトから文書をスクレイピングすることにしました（Ernsthausen, 2017）。
これらの文書はOCR（テキスト化）され、共同でタグ付けやレビューを行うためのカスタムWebベースのアプリケーションに読み込む必要がありました。
学習データを作成するために、数百の文書に手作業でタグ付けをしなければなりませんでした。機械学習で残りの10万件をランク付けした後、性的虐待について予測された6,000件の文書と、手作業で選んだキーワードを含む数千件の文書を読むのにさらに数カ月を要しました。
さらに、ストーリーを具体化するために、何百もの具体的な事件を調査するなど、その他の取材も必要でした。
過去のニュース記事や、関係者への個人的なインタビューなど、他の情報源も利用しました。
アルゴリズム（機械学習）の使用は、調査の重要な部分を占めています。しかし、それは（全体に占める）時間と労力のごく一部にすぎません。
データ・サイエンティストを対象とした調査では、仕事のほとんどがデータの「整理」と「クリーニング」であることが一貫して示されており、その割合は80％にも上ります。ジャーナリズムも同じです（Lohr, 2014）。
アルゴリズムは、ある種の魔法のようなものだと思われています。一見、複雑で不透明に見えるかもしれませんが、紛れもない力を持っています。
この魔法は、データを準備したり、長いリストをフォローアップしたりするありふれた仕事よりも、話をしていてずっと楽しいものです。技術者は、自分たちの技術を誇示したいのであって、その周辺で行われている同様に重要な仕事を誇示したいわけではありません。
新しく洗練されたツールに対するこのような偏見は、時としてジャーナリズムにも影響を及ぼします。しかし、私たちの第一の責任はジャーナリズムを遂行することであり、それには他のデータパイプラインにも取り組む必要があるのです。
一般的に、私たちはデータの準備に使われるツールを過小評価しています。OpenRefineは、あらゆる（データ）クリーニングタスクの長年のヒーローです。
Dedupe.ioは、機械学習を応用してデータベース内の重複した名前をマージします。
正規表現のような古典的なテキスト処理方法は、データ・ジャーナリストの全ての教育に含まれるべきです。私の現在のプロジェクトである「Workbench」は、時間がかかるがほとんど表に出ない、報道用のデータを準備する作業、つまり「アルゴリズム」の前に行われるすべての作業に焦点を当てています。
このプロジェクトは、記者が大規模なデータプロジェクトに共同で取り組み、機械も含めてお互いの仕事から学ぶことができるように、プロセス全体をより協力的にすることを目的としています。
アルゴリズムは報道にとって重要ですが、それを機能させるためには、データ駆動型ジャーナリズムの他のすべての部分について話し合わなければなりません。
目立って華やかでハイテクな部分だけでなく、ワークフロー全体の力を引き出す必要があるのです。
Works cited

Diakopoulos, N. (2019). Automating the news: How algorithms are rewriting the media. Harvard University Press.

Ernsthausen, J. (2017). Doctors and sex abuse. NICAR 2017, Jacksonville. docs.google.com/presentation/d/1keGeDk_wpBPQgUOOhbRarPPFbyCculTObGLeAhOMmEM/edit#slide=id.p

Lohr, S. (2014, August 17). For big-data scientists, “janitor work” is key hurdle to insights. The New York Times. www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html

Teegardin, C., Robbins, D., Ernsthausen, J., & Hart, A. (2016, July 5). License to betray. The Atlanta Journal-Constitution, Doctors & Sex Abuse. doctors.ajc.com/doctors_sex_abuse

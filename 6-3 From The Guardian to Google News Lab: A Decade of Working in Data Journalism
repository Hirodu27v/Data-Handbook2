ガーディアンからグーグルニュースラボへ：データジャーナリズムに携わって10年
Written by Simon Rogers
概要

データジャーナリズムの過去10年を、その名声の高い人物の一人（サイモン・ロジャース）の職業上の旅というレンズを通して振り返ります。

キーワード：データジャーナリズム、ガーディアンのデータブログ、ウィキリークス、オープンデータ、透明性、表計算ソフト
私がジャーナリストになりたいと思ったのは、小学校1年生と2年生の間くらいのことで、まさかデータを扱うことになるとは思いもよりませんでした。
今、毎日データを使って仕事をしていると、自分がいかに幸運だったかがわかります。慎重に練られたキャリアプランの結果ではないことは確かです。ただ、適切な時期に適切な場所にいただけなのです。
このような経緯は、2009年、そして19年のデータジャーナリズムの状況について多くのことを物語っています。
シカゴ出身で、ワシントン・ポスト紙に勤務した後、近隣住民を対象としたニュース・ディスカッション・サイト「EveryBlock」を立ち上げた開発者のエイドリアン・ホロバティが、ロンドンのファリングドン・ロードにあるガーディアン紙の教育センターで、ニュースルーム向けの講演をしに来たのです。
当時、私は、オンラインを経て、科学セクションの編集を担当し、紙媒体（当時は重心が置かれていた）のニュース編集者でした。
ホロバティが、データを使ってストーリーを伝え、人々が世界を理解する手助けをすることについて話せば話すほど、私の中で何かが動きました。
可能だということだけでなく、実際にやってみることができるのです。 もしかしたら、私はデータを扱うジャーナリストになれるかもしれない。"データジャーナリスト "です。
ニュースエディターとしてグラフィックデスクを担当したことで、マイケル・ロビンソンの才能あふれるチームの中で、私の世界の見方を変えたデザイナーと仕事をする機会を得ることができました。
そして、ビジュアル分野のポートフォリオが増えるにつれて、（そこには）たくさんの数字が蓄積されていることがわかりました。
ガーディアンのオープンAPIを立ち上げたマット・マカリスターは、これを "マザーロード "と表現しています。GDPデータ、二酸化炭素排出量、政府支出データ、その他多くのデータをきれいに整理し、すべてGoogleスプレッドシートとして保存し、次に必要なときにすぐに使えるようにしました。
このデータをオープンデータとして公開したら？PDFではなく、誰でもすぐに使える、アクセス可能なデータです。これが、ガーディアンのDatablogで行ったことです。
当初は200の異なるデータセットがありました。犯罪率、経済指標、紛争地域の詳細、さらにはファッション・ウィークやドクター・フーの悪役まで。そして、データはあらゆるものに応用できるのだということに気づきました。
しかし、それはまだ奇妙な存在でした。「データエディターという職業はほとんど普及しておらず、データチームを設置している報道局はほとんどありませんでした。
ニュースの打ち合わせで「データ」という言葉を使うだけで、鼻で笑われるような状況でした。これは「まともな」ジャーナリズムではない、というわけです。
しかし、2009年はオープンデータ革命の始まりの年でした。米国政府のデータハブであるdata.govは、その年の5月にわずか47件のデータセットでスタートしました。
世界中の国や都市がオープンデータポータルを立ち上げ、活動家たちはより多くのデータへのアクセスを要求していました。
読者の協力のもと、1年足らずで何千人もの国会議員の経費をクラウドソース化できました。同じ時期に、英国政府はCOINS（Combined Online Information System）という究極の支出データセットを発表しました。
ガーディアンのチームは読者にその探索を手伝ってもらうために、インタラクティブなエクスプローラーを作りました。
そのデータから記事が生まれると、「どうすればもっと多くのデータを入手できるか」という問いが出てきました。
（答えを得るには）そんなに待ちませんでした。その答えは、スウェーデンを拠点とする新組織「ウィキリークス」が、大胆な透明性アジェンダとも言えるものを用いてもたらしました。
ウィキリークスについて今日どう思うかは別にして、この組織が近年のデータジャーナリズムの歴史に与えた影響は誇張しすぎることはないでしょう。
ここには、まずアフガニスタン、次いでイラクの戦場から、何千もの詳細な記録が大量に投げ込まれたのです。
それは巨大なスプレッドシートの形で提供され、ガーディアンの調査チームが最初に扱うには大きすぎるものでした。
ベトナム戦争の実態を明らかにしたペンタゴン・ペーパーズ（米国防総省発行の文書）よりも規模が大きく、詳細で、死傷者数、地理的位置、詳細、カテゴリーを含む事件のリストも含まれていました。
例えば、イラクでは簡易爆弾の被害が増加し、道路が危険な状態になっていることが分かりました。そして、そのデータと熟練した戦争記者の伝統的な報道技術が組み合わさったとき、世界の戦争の見え方が変わったのです。
全世界にインパクトを与えるようなコンテンツを作ることは難しくありませんでした。例えば、スプレッドシートのジオデータはマッピングに適しており、それを支援する新しい無料ツールがあったのです。
Google Fusion Tablesです。そこで私たちは、イラクで少なくとも1人の死者が出ているすべての事件を大づかみで地図化しました。
24時間以内に、1時間で作ったコンテンツが世界中で見られるようになり、ユーザーは戦場をよりリアルに感じられるようになりました。
また、データが構造化されているため、グラフィック・チームは洗練されたリッチなビジュアルを作成し、より詳細なレポートを提供することができました。
ハンドブック初版公開前年の2011年末には、「暴動を読む」プロジェクトが、1960年代にフィル・マイヤーが行ったコンピュータ支援報道の技術を、イングランドで発生した暴力事件に応用しました（Robertson, 2011）。
マイヤーは、1960年代後半のデトロイト暴動に関する報道に社会科学の手法を応用したのです。
ガーディアンのポール・ルイスが率いるチームは、その年のイングランド全土で発生した暴力事件に敷衍し、その作業の重要な部分としてデータを取り入れたのです。
これらは、一面を飾る、データに基づいたストーリーでした。
しかし、私たちが情報を消費する方法にはもう一つの変化が起きており、それは急速に進展しました。2010年以前は、健康関連の記事以外で「バイラル」という言葉を聞いた記憶がありません。
今は違います。データジャーナリズムの台頭は、ソーシャルメディアの台頭とも重なります。
私たちは世界中のユーザーに記事を売り込むのにツイートを活用し、トラフィックが増え、この種のデータに基づくストーリーを探すユーザーが増えました。
ビジュアルや数値は、数秒で何千人もの目に触れることができるのです。ソーシャルメディアはジャーナリズムを一変させましたが、データ・ジャーナリズムの拡大はニッチから主流への移行を促したのです。
（具体例の）一つは、消費者との関係が変わったことです。以前は、記者の言葉は神聖なものとされていましたが、今は何百万人の中の一人の声に過ぎません。
あるデータセットでミスを犯せば、500人の人がすぐに知らせてくれるでしょう。Twitterでデザイナーと地図の配色について長く（そして深く）語り合い、そのために自分の仕事を変えたことを思い出します。
シェアすることで、私の仕事はより良いものになりました。
このようなコラボレーションの精神は、今日でもデータジャーナリズムに根差しています。ハンドブック初版は、ロンドンのモジラ・フェスの参加者によって作られました。
データに関するイベントが増えるにつれ、データジャーナリストが一緒に仕事をし、スキルを共有する機会も増えてきました。
イラクとウィキリークスの発表が大西洋を越えた協力の素晴らしい最初の例であったならば、これらは何百人もの記者を含む全世界的な報道に成長した実例です。
スノーデンのリークやパナマ文書は、記者が世界中で連携してストーリーを共有し、互いの仕事を発展させたという点で注目されました。
選挙当日の投票問題をリアルタイムで監視するために共同報道の手法を用いたElectionlandのような活動を考えてみるとよいでしょう。
私も参加し、リアルタイムでGoogleのデータを提供し、それらの懸念をリアルタイムで視覚化することに貢献しました。
今に至るまで、Electionlandは1日の取材活動としては史上最大規模であり、当日は1000人以上のジャーナリストが参加しました。Electionlandは、私たちが最初の数年間にやっていたことと、直結しているのです。
私はプロジェクトを列挙したいのではありません。ガーディアンだけでなく、世界中のニュースルームに共通するデータジャーナリズム初期の広がりを強調したいのです。
ニューヨークタイムズ、ロサンゼルスタイムズ、アルゼンチンのラ・ナシオンなど、世界中のジャーナリストがデータ主導のストーリーを革新的な方法で伝え、新しい働き方を見出しました。
これがハンドブック初版（制作）の背景だったのです。
アルゼンチンのラ・ナシオンがその良い例です。
熱心な記者たちでつくる小チームは、Tableau（当時は新しいツール）を使った可視化を独学で学び、これを情報の自由の記事と組み合わせて、中南米におけるデータジャーナリズムの口火を切りました。
データジャーナリズムは、少数の一匹狼の領域から、多くの主要なニュースルームで確立された手法になりました。しかし、当時から一つの傾向は明らかでした。
報道に新しい手法が導入されるたびに、データが重要な役割を果たすだけでなく、データ・ジャーナリストが台頭したのです。
3年足らずの間に、クラウドソーシングはニュースルームのツールとして定着し、ジャーナリストはデータを見つけ、データベースを使って膨大な量の文書を管理し、データセットを公開し、複雑なニュース記事にデータ駆動型の分析手法を適用するようになりました。
これは、ジャーナリズムの分野でのみ起こった発展ではありません。これらは、オープンデータ・ポータルの設置にとどまらず、国際的な透明性に関する大きな進展の影響に過ぎないのです。
（時代の流れが）Free Our Data、Open Knowledge Foundation、シビックテック・グループによるキャンペーンなど、英国政府に対する圧力を高め、ニュース・データセットを一般利用のために開放し、誰もが探索できるようにAPIを提供するよう求めたのである。
また、OpenRefine、Google Fusion Tables、Many Eyes、Datawrapper、Tableau Publicなど、強力な無料のデータ可視化・クリーニングツールへのアクセス向上も含まれています。
これらの無料ツールと多くの無料公共データへのアクセスが相まって、より多くの公共向け可視化およびデータプロジェクトの作成が促進されました。
The Texas TribuneやProPublicaなどのニュースルームは、このデータを中心に事業を展開するようになりました。
この仕組みがわかりましたか？データ、簡単な処理、データの可視化、さらにデータ......という好循環が生まれるのです。
データが世に出れば出るほど、そのデータを使った作業が増えれば増えるほど、より多くのデータを公開するよう求める圧力が強くなります。
私が「データ・ジャーナリズムは新しいパンク」という作品を書いたとき、その点を指摘していたのです。私たちは、創造性を自由に発揮できる場所にいるのです(Rogers, 2012)。
そしてまた、その仕事はやがて主流となるものでもありました。
データは万能ではありません。ジョナサン・グレイ (2012)が書いているように、「データ、データ技術、データ駆動型のあらゆるものに関する現在の盛り上がりは、この機械可読で構造化されたものこそが素晴らしいと思わせるかもしれません」。
それは、記者が組み立てなければならない証拠というパズルの1ピースに過ぎない。しかし、利用できるデータが増えれば増えるほど、その役割は変化し、さらに重要になります。
巨大なデータセットにアクセスし、分析できることが、私の次の転職の大きな動機でした。

In 2013, I got the chance to move to California and join Twitter as its first data editor—and it was clear that data had entered the vocabulary of mainstream publishing, certainly in the United States and Europe. A number of data journalism sites sprouted within weeks of each other, such as The New York Times’ Upshot and Nate Silver’s FiveThirtyEight.

Audiences out there in the world were becoming more and more visually literate and appreciative of sophisticated visualizations of complex topics. You will ask what evidence I have that the world is comfortable with data visualizations? I don’t have a lot beyond my experience that producing a visual which garners a big reaction online is harder than it used to be. Where we all used to react with “oohs and aahs” to visuals, now it’s harder to get beyond a shrug.

By the time I joined the Google News Lab to work on data journalism in 2015, it had become clear that the field has access to greater and larger data sets than ever before. Every day, there are billions of searches, a significant proportion of which have never been seen before. And increasingly reporters are taking that data and analyzing it, along with tweets and Facebook likes.3 This is the exhaust of modern life, turned around and given back to us as insights about the way we live today.

Data journalism is now also more widespread than it has ever been. In 2016, the Data Journalism Awards received a record 471 entries. But the 2018 awards received nearly 700, over half from small newsrooms, and many from across the world. And those entries are becoming more and more innovative. Artificial intelligence, or machine learning, has become a tool for data journalism, as evidenced by Peter Aldhous’ work at Buzzfeed (Aldhous, 2017).

Meanwhile access to new technologies like virtual and augmented reality open up possibilities for telling stories with data in new ways. As someone whose job is to imagine how data journalism could change—and what we can do to support it—I look at how emerging technologies can be made easier for more reporters to integrate into their work. For example, we recently worked with design studio Datavized to build TwoTone, a visual tool to translate data into sound.4

What does a data journalist at Google do? I get to tell stories with a large and rich collection of data sets, as well as getting to work with talented designers to imagine the future of news data visualization and the role of new technologies in journalism. Part of my role is to help explore how new technologies can be matched with the right use cases and circumstances in which they are appropriate and useful. This role also involves exploring how journalists are using data and digital technologies to tell stories in new ways. For example, one recent project, El Universal’s “Zones of Silence", demonstrated the use of AI in journalism, using language processing to analyze news coverage of drug cartel murders and compare them to the official data, the gap between the two being areas of silence in reporting. I helped them do it, through access to AI APIs and design resources.

The challenges are great, for all of us. We all consume information in increasingly mobile ways, which brings its own challenges. The days of full-screen complex visualizations have crashed against the fact that more than half of us now read the news on our phones or other mobile devices (a third of us read the news on the toilet, according to a Reuters news consumption study (Newman et al., 2017)). That means that increasingly newsroom designers have to design for tiny screens and dwindling attention spans.

We also have a new problem that can stop us learning from the past. Code dies, libraries rot and eventually much of the most ambitious work in journalism just dies. The Guardian’s MPs’ expenses, EveryBlock and other projects have all succumbed to a vanishing institutional memory. This problem of vanishing data journalism is already subject to some innovative approaches (as you can see from Broussard’s chapter in this book). In the long run, this requires proper investment and it remains to be seen if the community is sufficiently motivated to make it happen.

And we face a wider and increasingly alarming issue: Trust. Data analysis has always been subject to interpretation and disagreement, but good data journalism can overcome that. At a time when belief in the news and a shared set of facts are in doubt every day, data journalism can light the way for us, by bringing facts and evidence to light in an accessible way.

So, despite all the change, some things are constant in this field. Data journalism has a long history,5 but in 2009, data journalism seemed an important way to get at a common truth, something we could all get behind. Now that need is greater than ever before.

Footnotes

1. www.theguardian.com/politics/coins-combined-online-information-system

2. For more on large-scale collaborations around the Panama Papers, see Díaz-Struck, Gallego and Romera’s chapter in this volume.

3. For further perspectives on this, see the “Investigating Data, Platforms and Algorithms” section.

4. twotone.io

5. See, for example, the chapters by Anderson and Cohen in this volume.

Works cited

Aldhous, P. (2017, August 8). We trained a computer to search for hidden spy planes. This is what it found. BuzzFeed News. www.buzzfeednews.com/article/peteraldhous/hidden-spy-planes

Gray, J. (2012, May 31). What data can and cannot do. The Guardian. www.theguardian.com/news/datablog/2012/may/31/data-journalism-focused-critical

Newman, N., Fletcher, R., Kalogeropoulos, A., Levy, D. A. L., & Nielsen, R. K. (2017). Digital News Report 2017. Reuters Institute for the Study of Journalism. reutersinstitute.politics.ox.ac.uk/sites/default/files/Digital%20News%20Report%202017%20web_0.pdf

Robertson, C. (2011, December 9). Reading the riots: How the 1967 Detroit riots were investigated. The Guardian. www.theguardian.com/uk/series/reading-the-riots/2011/dec/09/all

Rogers, S. (2012, May 24). Anyone can do it. Data journalism is the new punk.The Guardian.www.theguardian.com/news/datablog/2012/may/24/data-journalism-punk


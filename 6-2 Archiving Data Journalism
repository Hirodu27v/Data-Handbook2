データジャーナリズムを記録する
Written by: Meredith Broussard
概要

この章では、データジャーナリズムのプロジェクトを記録する際の課題と、プロジェクトが将来にわたって確実に保存されるためにデータチームが取るべき措置について説明します。

キーワード：データジャーナリズム，アーカイブの実践，アーカイブ，デジタルアーカイブ，リンク切れ，ウェブアーカイビング
2012年に出版された『データジャーナリズムハンドブック』の初版で、データジャーナリズムのパイオニアであるスティーブ・ドイグは、お気に入りのデータストーリーの一つがトム・ハーグローブによる「殺人ミステリー」プロジェクトだと書いています1。
スクリップス・ハワード・ニュース・サービスが発行したこのプロジェクトでは、18万5000件の未解決殺人事件に関する人口統計学的に詳細なデータを調べ、どの殺人事件が関連しているかを示唆するアルゴリズムを構築しました。
関連性のある殺人は、連続殺人犯の仕業である可能性があります。「このプロジェクトにはすべてがある」とドイグは書いています。
「ハードワーク、政府自身よりも優れたデータベース、社会科学技術を使った巧妙な分析、読者が自分で調べることができるオンラインのインタラクティブなデータの提示」。
6年後のハンドブック第2版の時点では、このプロジェクトのURLは壊れていました（projects.scrippsnews.com/magazine/murder-mysteries）。このプロジェクトがウェブ上から消えていたのは、発行元のスクリプスハワードがなくなったからです。
スクリプスハワード・ニュース・サービスは何度も合併や再編を繰り返し、最終的にはローカルニュースネットワーク『USAトゥデイ』を発行するガネットと合併したのです。
人は転職し、メディア企業は変遷します。しかし、これはデータジャーナリズムのプロジェクトに悲惨な結果をもたらします（この問題については、Boss & Broussard, 2017; Broussard, 2014, 2015a, 2015b; Fisher & Klein, 2016などを参照してください）。
データプロジェクトは、紙の新聞や雑誌に掲載される「平凡な」テキストと画像の物語よりももろいのです。
通常、リンク切れはアーキビストにとって大きな問題ではありません。
LexisNexisやProQuestなどのデータベースプロバイダーを使えば、21世紀のどの日でもニューヨークタイムズの紙面を簡単に見つけることができるからです。
しかし、データストーリーの場合、リンク切れはより深刻です。データ・ジャーナリズムの記事は、従来のアーカイブには保存されておらず、Webから消えつつあるのです。
報道機関や図書館が行動を起こさない限り、将来の歴史家は、2017年のある日にボストン・グローブ紙が発行したすべての記事を読むことはできないだろう。
このことは、研究者にとっても、この分野の集合的な記憶にとっても、重大な意味を持ちます。ジャーナリズムはしばしば、"歴史の初稿 "と呼ばれます。もし、その初稿が不完全ならば、未来の学者はどうやって現代を理解するのでしょうか。
あるいは、記事がWebから消えてしまった場合、ジャーナリストはどのようにして個人的な仕事のポートフォリオを維持するのでしょう?
これは人間の問題であり、単なる計算上の問題ではないのです。データ・ジャーナリズムがなぜ後世のためにアーカイブされていないのかを理解するには、「通常の」ニュースがどのようにアーカイブされているかを知ることから始めるとよいでしょう。
すべての報道機関は、コンテンツ管理システム（CMS）と呼ばれるソフトウェアを使用しています。このシステムによって、報道機関は毎日作成する何百ものコンテンツをスケジュール管理し、公開する各コンテンツに一貫した視覚的外観と感触を与えることができるのです。
歴史的に、旧来の報道機関では、紙とWebで異なるCMSを使用してきました。WebのCMSでは、各ページに広告を埋め込むことができ、これが報道機関が収益を上げる方法の一つとなっています。
紙のCMSでは、印刷デザイナーが異なるバージョンのレイアウトを管理し、そのページを印刷所に送って印刷・製本します。通常、動画は別のCMSになります。ソーシャルメディアの投稿は、SocialFlowやHootsuiteなど別のアプリケーションで管理することもありますし、そうでないこともあります。
Lexis-Nexisや他の大手プロバイダーへのアーカイブのフィードは、紙媒体のCMSに接続されていることが多いようです。
報道機関の誰かがウェブCMSに接続することを忘れない限り、デジタルファーストのニュースは図書館やアーカイブが取得するデジタルフィードには含まれないのです。
これは、アーカイブが中立的な存在ではなく、人間による何が将来にとって重要か（そして何が重要でないか）を意図的に選択することに依存していることを思い知らせるのです。
ほとんどの人はこの時点で、"Internet Archiveはどうなんだ？"と尋ねます。Internet Archiveは宝であって、このグループはニュースサイトのスナップショットを捕らえるという立派な仕事をしています。
その技術は、最先端のデジタルアーカイブソフトウェアの一つです。しかし、彼らのアプローチは、すべてを捕捉しているわけではありません。Internet Archiveは、一般公開されているwebページのみを収集しています。
ログインが必要であったり、ペイウォールを導入していたりする報道機関は、Internet Archiveに自動的に保存されることはありません。
静的コンテンツであるWebページ、つまりプレーンHTMLは、最も簡単に保存できます。このようなページは Internet Archive に簡単に取り込まれます。JavaScriptやデータの可視化など、かつて「Web 2.0」と呼ばれたダイナミックなコンテンツは保存が非常に難しく、Internet Archiveに保存されることはあまりありません。
Internet Archive FAQには「動的ページには多くの種類があり、簡単にアーカイブに保存できるものと、完全に崩壊してしまうものがあります」と書かれています。
「動的なページが標準的なhtmlをレンダリングする場合、アーカイブは機能します。ページが元のホストとの対話を必要とするフォーム、JavaScript、その他の要素を含んでいる場合、アーカイブは元のサイトの機能を再現できません」 。
ダイナミックなデータビジュアライゼーションやニュースアプリは、現在最も先端的なデータジャーナリズムのストーリーですが、既存のウェブアーカイブ技術では捕捉することができません。また、さまざまな制度上の理由から、この種のストーリーはCMSの外部で構築される傾向があります。
のため、たとえデータの可視化やニュースアプリのアーカイブが可能だとしても（このアプローチでは一般的に不可能です）、自動フィードはCMSの内部にないため、それらを捉えることができません。
それは複雑な問題で、簡単な答えはありません。私はデータジャーナリスト、図書館員、コンピューター科学者のチームと一緒に、この茨の道を解決するための技術を開発しようとしています。
私たちは、再現可能な科学研究の手法を借りて、人々が明日のコンピュータで今日のニュースを読めるようにすることを目指しています。
私たちは、計算科学の実験で使用されるコード、データ、サーバー環境を収集するReproZipというツールを応用しています。
ReproZipは、Webrecorder.ioのようなツールと統合することで、ストーリーとソフトウェアの両方（の性格を併せ持つ）ニュースアプリを収集し保存することができると考えています。
Webやモバイルベースのデータジャーナリズム・プロジェクトは、他の幅広いメディア環境、ライブラリ、ブラウザ機能、Web実体（これらも継続的に変化する可能性があります）に依存し、それらと関連して存在するため、ReproZipを使用して、複雑なデータ・ジャーナリズム・オブジェクトをWeb上で機能させるためのリモート・ライブラリーとコードを収集し、保存できることが期待されます。
私たちの仮説を証明するには、あと1、2年かかるでしょう。
その間、データ・ジャーナリズムを将来にわたって確実に保存するために、すべてのデータ・チームができることがいくつかあります。
動画を撮る。この戦略は、ビデオゲームの保存から借用したものです。ゲーム機がなくなっても、ビデオでプレイスルーすれば、元の環境でゲームを見ることができる。データジャーナリズムのストーリーにも同じことが言えます。
映像は、その映像が示すものを説明するプレーンテキストのメタデータとともに、一カ所に保存します。
新しいビデオ・フォーマット（VHSからDVDへ、あるいはDVDからストリーミング・ビデオへ）が登場するたびに、すべてのビデオをこの新しいフォーマットにアップグレードします。
後世に残すために縮小版を作る。Django-bakeryのようなライブラリを使えば、動的なページを静的なページとしてレンダリングできます。
これは「ベイクアウト」と呼ばれることもあります。何千ものレコードを持つデータベースでも、それぞれの動的なレコードを静的なページとしてベイクアウトすれば、ほとんどメンテナンスが不要になります。
理論的には、これらの静的ページをすべて組織のコンテンツ管理システムにインポートすることができます。ベイクアウトは、ローンチ当初から行う必要はありません。
データプロジェクトを動的なサイトとして立ち上げ、数ヵ月後にトラフィックが減少したら、静的なサイトに変更することも可能です。
一般的には、できるだけシンプルなバージョンを作成し、同時期に公開された他のすべてのストーリーと同じデジタルロケーションに置いて、作品をアーカイブシステムに適応させるとよいでしょう。
将来について考える。ジャーナリストは、記事を公開して次の仕事に移ることを考えがちです。
その代わりに、データストーリーを発表するのと同時に、そのストーリーが終わるまでの計画を立ててみましょう。
OpenNewsのブログSourceにあるマット・ウェイトのストーリー「Kill All Your Darlings」は、データジャーナリズムの記事のライフサイクルについて考える素晴らしいガイドとなるものです。
いずれ、あなたは昇進するか、新しい組織に移ることになります。あなたのデータジャーナリズムが、あなたの退職後も生き残るようにしたいものです。
図書館、知の記録機関、商業アーカイブと協力する。個人のジャーナリストとして、あなたは自分の作品のコピーを絶対に取っておくべきでしょう。
しかし、将来ジャーナリズムを探すときに、あなたのクローゼットの中の箱やハードディスク、あるいはあなたの個人ウェブサイトを見る人はいないでしょう。
彼らはLexis-NexisやProQuestなどの巨大な商用リポジトリを探すのです。
商業作品の保存とデジタル・アーカイブの詳細については、キャスリン・ハンセンとノラ・ポールの共著、 「Future-Proofing the News:Preserving the First Draft of History (2017) 」 を参照してください。これは、ニュース・アーカイブの状況と、ニュースの保存に関する技術的、法的、組織的な課題を理解するための標準的なガイドです。
Footnotes

1. www.murderdata.org

Works Cited

Boss, K., & Broussard, M. (2017). Challenges of archiving and preserving born-digital news applications. IFLA Journal, 43(2), 150–157. doi.org/10.1177/0340035216686355

Broussard, M. (2014, April 23). Future-proofĳing news apps. MediaShift. mediashift.org/2014/04/future-proofing-news-apps/

Broussard, M. (2015a). Preserving news apps present huge challenges. Newspaper Research Journal, 36(3), 299–313. doi.org/10.1177/0739532915600742

Broussard, M. (2015b, November 20). The irony of writing about digital preserva- tion. The Atlantic.www.theatlantic.com/technology/archive/2015/11/the-irony-of-writing-about-digital-preservation/416184/

Fisher, T., & Klein, S. (2016). A conceptual model for interactive databases in news. GitHub. github.com/propublica/newsappmodel

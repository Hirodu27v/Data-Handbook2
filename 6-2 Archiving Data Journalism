データジャーナリズムを記録する
Written by: Meredith Broussard
概要

この章では、データジャーナリズムのプロジェクトを記録する際の課題と、プロジェクトが将来にわたって確実に保存されるためにデータチームが取るべき措置について説明します。

キーワード：データジャーナリズム，アーカイブの実践，アーカイブ，デジタルアーカイブ，リンク切れ，ウェブアーカイビング
2012年に出版された『データジャーナリズムハンドブック』の初版で、データジャーナリズムのパイオニアであるスティーブ・ドイグは、お気に入りのデータストーリーの一つがトム・ハーグローブによる「殺人ミステリー」プロジェクトだと書いています1。
スクリップス・ハワード・ニュース・サービスが発行したこのプロジェクトでは、18万5000件の未解決殺人事件に関する人口統計学的に詳細なデータを調べ、どの殺人事件が関連しているかを示唆するアルゴリズムを構築しました。
関連性のある殺人は、連続殺人犯の仕業である可能性があります。「このプロジェクトにはすべてがある」とドイグは書いています。
「ハードワーク、政府自身よりも優れたデータベース、社会科学技術を使った巧妙な分析、読者が自分で調べることができるオンラインのインタラクティブなデータの提示」。
6年後のハンドブック第2版の時点では、このプロジェクトのURLは壊れていました（projects.scrippsnews.com/magazine/murder-mysteries）。このプロジェクトがウェブ上から消えていたのは、発行元のスクリプスハワードがなくなったからです。
スクリプスハワード・ニュース・サービスは何度も合併や再編を繰り返し、最終的にはローカルニュースネットワーク『USAトゥデイ』を発行するガネットと合併したのです。
人は転職し、メディア企業は変遷します。しかし、これはデータジャーナリズムのプロジェクトに悲惨な結果をもたらします（この問題については、Boss & Broussard, 2017; Broussard, 2014, 2015a, 2015b; Fisher & Klein, 2016などを参照してください）。
データプロジェクトは、紙の新聞や雑誌に掲載される「平凡な」テキストと画像の物語よりももろいのです。
通常、リンク切れはアーキビストにとって大きな問題ではありません。
LexisNexisやProQuestなどのデータベースプロバイダーを使えば、21世紀のどの日でもニューヨークタイムズの紙面を簡単に見つけることができるからです。
しかし、データストーリーの場合、リンク切れはより深刻です。データ・ジャーナリズムの記事は、従来のアーカイブには保存されておらず、Webから消えつつあるのです。
報道機関や図書館が行動を起こさない限り、将来の歴史家は、2017年のある日にボストン・グローブ紙が発行したすべての記事を読むことはできないだろう。
このことは、研究者にとっても、この分野の集合的な記憶にとっても、重大な意味を持ちます。ジャーナリズムはしばしば、"歴史の初稿 "と呼ばれます。もし、その初稿が不完全ならば、未来の学者はどうやって現代を理解するのでしょうか。
あるいは、記事がWebから消えてしまった場合、ジャーナリストはどのようにして個人的な仕事のポートフォリオを維持するのでしょう?
これは人間の問題であり、単なる計算上の問題ではないのです。データ・ジャーナリズムがなぜ後世のためにアーカイブされていないのかを理解するには、「通常の」ニュースがどのようにアーカイブされているかを知ることから始めるとよいでしょう。
すべての報道機関は、コンテンツ管理システム（CMS）と呼ばれるソフトウェアを使用しています。このシステムによって、報道機関は毎日作成する何百ものコンテンツをスケジュール管理し、公開する各コンテンツに一貫した視覚的外観と感触を与えることができるのです。
歴史的に、旧来の報道機関では、紙とWebで異なるCMSを使用してきました。WebのCMSでは、各ページに広告を埋め込むことができ、これが報道機関が収益を上げる方法の一つとなっています。
紙のCMSでは、印刷デザイナーが異なるバージョンのレイアウトを管理し、そのページを印刷所に送って印刷・製本します。通常、動画は別のCMSになります。ソーシャルメディアの投稿は、SocialFlowやHootsuiteなど別のアプリケーションで管理することもありますし、そうでないこともあります。
Lexis-Nexisや他の大手プロバイダーへのアーカイブのフィードは、紙媒体のCMSに接続されていることが多いようです。
報道機関の誰かがウェブCMSに接続することを忘れない限り、デジタルファーストのニュースは図書館やアーカイブが取得するデジタルフィードには含まれないのです。
これは、アーカイブが中立的な存在ではなく、人間による何が将来にとって重要か（そして何が重要でないか）を意図的に選択することに依存していることを思い知らせるのです。
ほとんどの人はこの時点で、"Internet Archiveはどうなんだ？"と尋ねます。Internet Archiveは宝であって、このグループはニュースサイトのスナップショットを捕らえるという立派な仕事をしています。
その技術は、最先端のデジタルアーカイブソフトウェアの一つです。しかし、彼らのアプローチは、すべてを捕捉しているわけではありません。Internet Archiveは、一般公開されているwebページのみを収集しています。
ログインが必要であったり、ペイウォールを導入していたりする報道機関は、Internet Archiveに自動的に保存されることはありません。
静的コンテンツであるWebページ、つまりプレーンHTMLは、最も簡単に保存できます。このようなページは Internet Archive に簡単に取り込まれます。JavaScriptやデータの可視化など、かつて「Web 2.0」と呼ばれたダイナミックなコンテンツは保存が非常に難しく、Internet Archiveに保存されることはあまりありません。
Internet Archive FAQには「動的ページには多くの種類があり、簡単にアーカイブに保存できるものと、完全に崩壊してしまうものがあります」と書かれています。
「動的なページが標準的なhtmlをレンダリングする場合、アーカイブは機能します。ページが元のホストとの対話を必要とするフォーム、JavaScript、その他の要素を含んでいる場合、アーカイブは元のサイトの機能を再現できません」 。
ダイナミックなデータビジュアライゼーションやニュースアプリは、現在最も先端的なデータジャーナリズムのストーリーですが、既存のウェブアーカイブ技術では捕捉することができません。また、さまざまな制度上の理由から、この種のストーリーはCMSの外部で構築される傾向があります。
のため、たとえデータの可視化やニュースアプリのアーカイブが可能だとしても（このアプローチでは一般的に不可能です）、自動フィードはCMSの内部にないため、それらを捉えることができません。
それは複雑な問題で、簡単な答えはありません。私はデータジャーナリスト、図書館員、コンピューター科学者のチームと一緒に、この茨の道を解決するための技術を開発しようとしています。
私たちは、再現可能な科学研究の手法を借りて、人々が明日のコンピュータで今日のニュースを読めるようにすることを目指しています。
私たちは、計算科学の実験で使用されるコード、データ、サーバー環境を収集するReproZipというツールを応用しています。
ReproZipは、Webrecorder.ioのようなツールと統合することで、ストーリーとソフトウェアの両方（の性格を併せ持つ）ニュースアプリを収集し保存することができると考えています。
Webやモバイルベースのデータジャーナリズム・プロジェクトは、他の幅広いメディア環境、ライブラリ、ブラウザ機能、Web実体（これらも継続的に変化する可能性があります）に依存し、それらと関連して存在するため、ReproZipを使用して、複雑なデータ・ジャーナリズム・オブジェクトをWeb上で機能させるためのリモート・ライブラリーとコードを収集し、保存できることが期待されます。
私たちの仮説を証明するには、あと1、2年かかるでしょう。
その間、データ・ジャーナリズムを将来にわたって確実に保存するために、すべてのデータ・チームができることがいくつかあります。
動画を撮る。この戦略は、ビデオゲームの保存から借用したものです。ゲーム機がなくなっても、ビデオでプレイスルーすれば、元の環境でゲームを見ることができる。データジャーナリズムのストーリーにも同じことが言えます。
映像は、その映像が示すものを説明するプレーンテキストのメタデータとともに、一カ所に保存します。
新しいビデオ・フォーマット（VHSからDVDへ、あるいはDVDからストリーミング・ビデオへ）が登場するたびに、すべてのビデオをこの新しいフォーマットにアップグレードします。

Make a scaled-down version for posterity. Libraries like Django-bakery allow dynamic pages to be rendered as static pages. This is sometimes called “baking out”. Even in a database with thousands of records, each dynamic record could be baked out as a static page that requires very little maintenance. Theoretically, all of these static pages could be imported into the organization’s content management system. Baking out doesn’t have to happen at launch. A data project can be launched as a dynamic site, then it can be transformed into a static site after traffic dies down a few months later. The general idea is to adapt your work for archiving systems by making the simplest possible version, then make sure that simple version is in the same digital location as all of the other stories published around the same time.

Think about the future. Journalists tend to plan to publish and move on to the next thing. Instead, try planning for the sunset of your data stories at the same time that you plan to launch them. Matt Waite’s story “Kill All Your Darlings” on Source, the OpenNews blog, is a great guide to how to think about the life cycle of a data journalism story. Eventually, you will be promoted or will move on to a new organization. You want your data journalism to survive your departure.

Work with libraries, memory institutions and commercial archives. As an individual journalist, you should absolutely keep copies of your work. However, nobody is going to look in a box in your closet or on your hard drive, or even on your personal website, when they look for journalism in the future. They are going to look in Lexis-Nexis, ProQuest or other large commercial repositories. To learn more about commercial preservation and digital archiving, Kathleen Hansen and Nora Paul’s book Future-Proofing the News: Preserving the First Draft of History (2017) is the canonical guide for understanding the news archiving landscape as well as the technological, legal and organizational challenges to preserving the news.

Footnotes

1. www.murderdata.org

Works Cited

Boss, K., & Broussard, M. (2017). Challenges of archiving and preserving born-digital news applications. IFLA Journal, 43(2), 150–157. doi.org/10.1177/0340035216686355

Broussard, M. (2014, April 23). Future-proofĳing news apps. MediaShift. mediashift.org/2014/04/future-proofing-news-apps/

Broussard, M. (2015a). Preserving news apps present huge challenges. Newspaper Research Journal, 36(3), 299–313. doi.org/10.1177/0739532915600742

Broussard, M. (2015b, November 20). The irony of writing about digital preserva- tion. The Atlantic.www.theatlantic.com/technology/archive/2015/11/the-irony-of-writing-about-digital-preservation/416184/

Fisher, T., & Klein, S. (2016). A conceptual model for interactive databases in news. GitHub. github.com/propublica/newsappmodel

ニュースルームにおけるデータを活用したコーディング
Written by Basile Simon

概要

ニュースルームは、コーダーや技術志向のジャーナリストにとって固有の課題を抱えています。

キーワード：計算論的ジャーナリズム、プログラミング、データクリーニング、データベース、データ・ビジュアライゼーション

必然的に、データとコードが仲間になるポイントがあります。データセットが大きすぎてGoogle Sheets（の処理）が遅くなったとき、Excelの数式が難解になったとき、何百行ものデータを理解するのが不可能になったときなどです。
コーディングは、データをよりシンプルに、よりエレガントに、繰り返しを少なく、より繰り返し可能にしてくれます。スプレッドシートを放棄することを意味するのではなく、スプレッドシートが数多くのツールの一つになることを意味しています。
データ・ジャーナリストは、必要に応じて様々なテクニックを駆使しています。例えば、Python notebooksでデータをスクレイピングしたり、その結果をスプレッドシートに投げ込んだり、Refineでクリーニングするために、コピーアンドペーストしたりします。
人によって学ぶプログラミング言語や技術は異なり、ニュースルームによっても制作する言語は異なります。
これは、組織が社内で使用する一連のテクノロジー「スタック」を選択することにも起因しています。
例えば、ロンドンのタイムズ紙では、データ、ビジュアル、開発のほとんどがR、JavaScript、Reactで行われていますし、アメリカのプロパブリカでは、ウェブアプリの多くにRubyが使われています。
ツールを選択するのは個人であることが多いですが、報道機関の慣習や文化がこれらの選択に大きく影響することもあります。
たとえば、BBCはデータ可視化のワークフローを徐々にRに移行しており（BBC Data Journalism team, n.d.）、エコノミスト誌は世界的に有名なビッグマック指数をExcelベースの計算からRとReact/d3.jsのダッシュボードに移行しました（González et al.2018）。
多くの選択肢があり、唯一の正解はありません。
初心者にとって朗報なのは、多くの基本概念がすべてのプログラミング言語に当てはまるということです。
データポイントをリストに格納する方法（スプレッドシートの行や列に格納するのと同じ）と、Pythonでさまざまな操作を行う方法を理解すれば、JavaScript、R、Rubyで同じことを行うには、構文を学ぶだけでよいのです。
本章では、データ・ジャーナリズムのコーディングは、三つのコア領域に分割できると考えます。
データ作業-スクレイピング、クリーニング、統計（スプレッドシートでできる作業）
バックエンド作業-データベース、サーバー、APIなどの難解な世界
フロントエンド作業-インタラクティブなデータ・ビジュアライゼーションなど、ウェブブラウザで行う作業のほとんど
本章では、データ・ジャーナリストがニュースルームでコードを扱う際に日常的に直面する、(a)学習時間、(b)期限付きの作業、(c)コードのレビューなどの制約によって、これらの異なる分野の作業がどのように形成されるかを探ります。

Time to Learn

One of the wonderful traits uniting the data journalism community is the appetite to learn. Whether you are a reporter keen on learning the ropes, a student looking to get a job in this field or an accomplished practitioner, there is plenty to learn. As technology evolves very quickly, and as some tools fall out of fashion while others are created by talented and generous people, there are always new things that can be done and learned. There are often successive iterations and versions of tools for a given task (e.g., libraries for obtaining data from Twitter’s API). Tools often build and expand on previous ones (e.g., extensions and add-ons for the D3 data visualization library). Coding in data journalism is thus an ongoing learning process which takes time and energy, on top of an initial investment of time to learn.

One issue that comes with learning programming is the initial reduction of speed and efficiency that comes with grappling with unfamiliar concepts. Programming boot camps can get you up to speed in a matter of weeks, although they can be expensive. Workshops at conferences are shorter and cheaper, and for beginners as well as advanced users. Having time to learn on the clock, as part of your job, is a necessity. There you will face real, practical problems, and if you are lucky you will have colleagues to help you. There’s a knack to finding solutions to your problems: Querying for issues over and over again and developing a certain “nose” for what is causing an issue.

This investment in time and resources can pay off: Coding opens many new possibilities and provides many rewards. One issue that remains at all stages of experience is that it is hard to estimate how long a task will take. This is challenging, because newsroom work is made of deadlines.

Working With Deadlines

Delivering on time is an essential part of the job in journalism. Coding, as reporting, can be unpredictable. Regardless of your level of experience, delays can—and invariably will—happen.

One challenge for beginners is slowdown caused by learning a new way to work. When setting off to do something new, particularly in the beginning of your learning, make sure you leave yourself enough time to be able to complete your task with a tool you know (e.g., spreadsheet). If you are just starting to learn and strapped for time, you may want to use a familiar tool and wait until you have more time to experiment.

When working on larger projects, tech companies use various methods to break projects down into tasks and sub-tasks (until the tasks are small and self-contained enough to estimate how long they will take) as well as to list and prioritize tasks by importance.

Data journalists can draw on such methods. For example, in one The Sunday Times project on the proportion of reported crimes that UK police forces are able to solve, we prioritized displaying numbers for the reader’s local area. Once this was done and there was a bit of extra time, we did the next item on the list: A visualization comparing the reader’s local area to other areas, and the national average. The project could have gone to publication at any point thanks to how we worked. This iterative workflow helps you focus and manage expectations at the same time.

Reviewing Code

Newsrooms often have systems in place to maintain standards for many of their products. A reporter doesn’t simply file their story and it gets printed: It is scrutinized by both editors and sub-editors.

Software developers have their own systems to ensure quality and to avoid introducing bugs to collaborative projects. This includes “code reviews,” where one programmer submits their work and others test and review it, as well as automated code tests.

According to the 2017 Global Data Journalism Survey, 40% of responding data teams were three to five members and 30% of them counted only one or two members (Heravi, 2017). These small numbers pose a challenge to internal code reviewing practices. Data journalists thus often work on their own, either because they don’t have colleagues, because there are no peer-review systems in place or because there is no one with the right skills to review their code.

Internal quality control mechanisms can therefore become a luxury that only a few data journalism teams can afford (there are no sub-editors for coding!). The cost of not having such control is potential bugs left unattended, sub-optimal performance or, worst of all, errors left unseen. These resource constraints are perhaps partly why it is important for many journalists to look for input on and collaboration around their work outside their organizations, for example from online coding communities.1

Footnotes

1. More on data journalism code transparency and reviewing practices can be found in chapters in this volume by Leon and Mazotte.

Works Cited

BBC Data Journalism team. (n.d.). What software do the BBC use [Interview].warwick.ac.uk/fac/cross_fac/cim/news/bbc-r-interview/

González, M., Hensleigh, E., McLean, M., Segger, M., & Selby-Boothroyd, A. (2018, August 6). How we made the new Big Mac Index interactive. Source. https:// source.opennews.org/articles/how-we-made-new-big-mac-index-interactive/ Heravi, B. (2017, August 1). State of data journalism globally: First insights into the global data journalism survey. Medium. medium.com/ucd-ischool/state-of-data-journalism-globally-cb2f4696ad3d

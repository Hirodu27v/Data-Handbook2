データジャーナリズムは何のためにあるのか？キャッシュ、クリック、カットとトライ
Written by Nikki Usher
概要

商業的なデータジャーナリズムの金銭的インセンティブと意図せざる結果を取り上げる。

キーワード：ジャーナリズム、データフィケーション、誤情報、政治経済、選挙、実験
FiveThirtyEightの2016年のインタラクティブな選挙マップ予測を毎日更新するのは、政治家からジャーナリスト、学生、政府職員まで、ワシントン市民の間では儀式的なものと化していました。
ニューヨークタイムズのUpshot世論調査アグリゲーターを愛用している人もいれば、よりオッズにこだわる人はReal Clear Politicsを、よりエキゾチックな趣味を持つ人はThe Guardianの米国選挙報道を利用する人もいました。
こうした人々にとって、ハンガーゲームの様相を呈する米国大統領選挙でヒラリー・クリントンに有利なオッズがある限り、世界はすべて順調であり、スプレッドが大きければ大きいほど良いということになるのでした。
この物語の結末はご存じでしょう。ネイト・シルバーのマップでは、選挙当日になっても、ヒラリー・クリントンが71.4%で勝利する可能性が高いとされていました（が、結果は逆でした）。
2016年のアメリカ大統領選挙を乗り越えるべき時期が来ているのではないでしょうか。
選挙マップへの執着は、定期的に実施される国政選挙がある米国の（人々の）娯楽なのかもしれません-とはいえ、世界中のオーディエンスも注目していないわけではないのです（N. P. Lewis & Waters, 2018）。
しかし、リンク切れにならない限り、この時の選挙マップは存在し続け、ジャーナリストとクリントン支持者の両方を悩ませるとともに、共和党が敵とする「時代遅れのメディア」が「フェイクニュース」 であると思い出させるためのネタを提供しています。
政治はともかく、2016年の米大統領選はデータジャーナリストにとって忘れてはならないものです。
たとえ定量化が誰の目にも正しかったとしても、マッピングと可視化の失敗は、ジャーナリストの認識力に関する主張（あるいはもっと単純に、「公認の知識人」であるという主張）を解体するための、もう一つの道具となったのです。
データジャーナリズムを選挙予測と一緒くたにするのは不公平でしょう。特に世界的に見れば、データジャーナリズムはそれ以上のものであることは間違いないが、データジャーナリズムの究極の貢献は、このようなもののように見えることがある。
無限に続く地図、クリック可能なチャート、計算の厳密さや統計的な腕前とは関係なく、ユーザーエラーや単純化しすぎ、疎外を踏襲しがちな計算機などです。
このハンドブックの第2版を手にした今、私たちはデータジャーナリズムが成熟し、自省する段階に達したと宣言することができます。そして、それゆえに、"何のためのデータ・ジャーナリズムなのか？"を問うことが重要なのです。
データジャーナリズムは、今日、ジャーナリズムを再構築し、再活性化するための可能性を示唆しているに過ぎません。このハンドブックの初版は、2011年にMozilla Festivalで行われた大人数の共同プロジェクトとして始まりました。
この取り組みを私は見ていましたが、すぐに、実際に目に見える成果として実現することはないだろうと考えていました（私は間違っていました）。
この第2版は、アムステルダム大学出版局が発行し、シカゴ大学出版局が寄稿者を募って米国で配布しており、データジャーナリズムの自由な性質が、プロ意識、秩序、正当性と引き換えにある程度交換されてきたことを示唆しています。
データジャーナリズムは主流となり、ジャーナリズム関連の学校で教えられ、ニュースルームにも組み込まれています（Usher, 2016）。
データジャーナリズムは標準化されており、過去5～7年間ほとんど変化していません。国横断的なデータジャーナリズムコンテストを検証すると、形式とトピック（最も多いのは政治）の革新は停滞し、地図とチャートが依然として主流であることがわかります（Loosen et al.、2020）。
インタラクティブ性は、情報可視化の関係者が「入門レベルのテクニック」と考えるものに限られており（Young et al.、2018）、さらに、データジャーナリズムは「動的、有向、加重グラフ」の可視化には十分に至っていないのです（Stoiber et al.、2015）。
データジャーナリストはまだ、オリジナルの「ビッグ・データ」ではなく、前処理されたデータを扱っています--そしてこのデータは、インターネットサービスプロバイダーが収集するような深さとサイズのマルチレベルデータではなく、せいぜい「ビッグ的」な政府データです。
この批評は、米国中心ではないにせよ、主に欧米中心の視点からなされたものですが、だからといって、私が提唱する本質的な行動を促す呼びかけが損なわれたわけではありません。
データ・ジャーナリストは、ジャーナリズムのための革命的な道具箱の上に座っているようなもので、まだ解き放たれていません。
しかし、この革命がうまく機能しなければ、ユーザー体験とニュース消費者の知識欲の両方をさらに損ない、最悪の場合、ニュースに対する不信感をさらに募らせることになります。
データジャーナリズムが過去5～10年間と同じような姿を続けるだけなら、デジタルとプラットフォームの時代におけるジャーナリズムの大義を推進することにはほとんどならないでしょう。
そこで、この本質的な問い（「データ・ジャーナリズムは何のためにあるのか」）を問い直すために、データジャーナリストと、データにあまり詳しくないがウェブにどっぷり浸かってビデオやオーディオやコードを扱うジャーナリスト、そして彼らをつつく学者たちが、データ・ジャーナリズムの原点、現在の根拠、未来を再考する必要があると提案します。
米国におけるデータジャーナリズム:起源の物語
起源の物語とは、私たちがどのように、そしてなぜ存在するようになったのかについて自分自身に語りかける物語であり、バラ色の眼鏡をかけ、現実よりも自慢に満ちていることが多いものです。
米国におけるデータジャーナリズムの原点は、次のようなものである。データ・ジャーナリズム以前の原初的な世界では、データジャーナリズムはコンピュータ支援報道として存在し、あるいは米国ではそう呼ばれていて、ジャーナリズムに社会科学の厳密性をもたらす機会を提供していた。
データジャーナリズムがWebに導入されたという神話の中で、データ・ジャーナリストは、21世紀の優れた計算能力を備えたパワーアップした調査ジャーナリストとなり、データ（または文書）を解放して、他の方法では伝えられないようなストーリーを伝えるのを助けるとされています。
単に記事を調査するだけでなく、データジャーナリストは新しいウェブスキルによってジャーナリズムを救うこともでき、ニュース消費者が喜び、学び、そしてもちろんクリックするニュースに、ある程度の透明性、パーソナライゼーション、そして双方向性をもたらした。
単にストーリーを調査するだけでなく、データジャーナリストは、その新しいウェブ技術によってジャーナリズムを救うことができた。ニュース消費者が評価し、そこから学び、もちろんクリックするようなレベルの透明性、個別化、双方向性をニュースにもたらした。
いわば、かつてのウェブのストーリーとは、決して同じものではなかったのです。
データジャーナリズムは、ジャーナリズムの質的評価に欠けていた誤りを正し、切望されていた客観的な基盤を提供し、それを、一つの報道機関から計算負荷を取り除く強力なクラウドベースのサーバーを備えた現在のリアルタイム・インタラクティブ・デジタル環境以前には想像もつかない規模と能力で行います。
成功の初期の兆候は、前進への道筋を示し、一般の読者を調査協力者や市民科学者へと変えてしまうことさえあります。
例えば、The Guardianが議員の経費スキャンダルを報道したことや、ニューヨーク市の公共ラジオ局WNYCの 「Cicada Tracker」 プロジェクトでは、地域住民に土壌温度計を作らせて、おそるべき夏の虫（セミ）の到来を記録するのに協力させました。
そして、ジャーナリズム、計算、群衆、データ、テクノロジーのこの刺激的な編成は続き、真実を正義へと押し上げることになるのです。
現在: 「ハッカー・ジャーナリスト」 はただの (退屈な) ニュースルーム従業員
現在も、今日のデータ・ジャーナリストが自分たちに言い聞かせてきた原点は、ビジョンも現実も大きくは変わっていない。そこで登場したのが、2種類のデータ・ジャーナリズムです。
ジャーナリズムの崇高なマントルを前面に押し出した「調査型」データ・ジャーナリズムと、最新のバイラル・クリックの興味に合わせて最適化できるデイリーデータ・ジャーナリズムです。
これには、ASAPのジャーナリズムの地図作成の取り組みから、世論調査や調査研究を、ジャーナリズムの虚飾と容易に共有できるミームに変えることまで、幅広い意味を持ちえます。
データジャーナリズムは、よく言えば退屈で、過度に専門的になり、悪く言えば、デジタル収入を得るためのもう一つの戦略になってしまったのです。
データジャーナリズムは、私たちが知っているジャーナリズムを一変させることができるのに、今のところそうなっていないといっても過言ではないでしょう。
2011年のMozFestでは、ボストン・グローブ紙のホームページのモックアップのリード画像に、誰でも自分の顔を表示できるプラグインのようなものが、このフェスティバルの主役でした。
それはそれで楽しかったのですが、ボストン・グローブは、ユーザーが作成したコンテンツを、何の事前フィルタリングもせずに、実際にホームページで使用することを許可するつもりはなかったことは確かです。
同様に、最初のデータ・ジャーナリズム・ハンドブックが誕生した頃、データ・ジャーナリストは「ハッカー・ジャーナリスト」であり、テクノロジーからジャーナリズムへ、少なくともオープンソースとハッキングの精神を使って、従来のジャーナリズムのプロセスに逆らうプロジェクトを触発し、実験、不完全、遊び心を提供し、形式や内容では優れていないかもしれないが、それでもジャーナリズムをハックできる何かを生み出すと考えられていました (S.C.Lewis & Usher, 2013)。
2011年には、業界の外側にいる人々がジャーナリズムに進出するという話でしたが、2018年には、業界関係者がジャーナリズムのプログラミングをプロ化するという話になっており、5年の間に、革新と発明の精神は、明らかに企業的で、明らかにホワイトカラー的で、明らかに楽しくなくなっています（S. C. Lewis & Usher, 2016）。
退屈でもいいし、それなりの役割もあります。データ・ジャーナリズムの専門化は、「英雄としてのデータ・ジャーナリスト」という自己認識によって正当化されてきました。
データジャーナリストは、異なる価値観（例：コラボレーション、透明性）とスキル（可視化、各種計算スキル）のおかげで、新しい方法で権力に真実をもたらすことができる人たちであると考えられてきました。
パナマ文書やパラダイス文書は、このビジョンを最もよく表現しているものの一つでしょう。
しかし、調査データジャーナリズムには、単なるデータ解析をはるかに超える時間、労力、専門知識が必要であり、主にインタビュー、現地取材、文書など、データ以外の昔ながらの情報源が含まれています。
定期的に発生する画期的な調査報道は、努力が足りないわけではありませんが、撞着語法のようなものです。
ヨーロッパのデータ・ジャーナリズム・ネットワーク、米国の非営利ニュース研究所、Global Investigative Journalism Networkはいずれも、調査活動のための膨大なネットワークを紹介しています。
実際、ゲームチェンジャーとなるような調査は簡単には得られない。だからこそ、こうしたハイレベルな成功例は一般に十指に満たず、2010年のThe Guardianによる国会議員の経費の例のようなクラウドソースによる調査の成功は、まだ新しいものに置き換えられていないのです。
データジャーナリズムに関しては、過去は序章である。2012年にピューリッツァー賞を受賞したニューヨークタイムズの革命的な没入型ストーリーテリングプロジェクト、"Snow Fall "は、2017年12月に "Deliverance from 27,000 Feet" または "Everest" として登場しました。
5年後、ニューヨークタイムズ紙はまた別の長編記事として雪山の災害についての長い記事を取り上げました(著者は同じでジョン・ブランチ)。
この5年間で、「Snowfall」または「Snowfalled」は、ストーリーに派手なインタラクティブ機能を加えることを意味する社内外の略語となったのでした。
2012年以降、データジャーナリストが、どんなストーリーでも自動でSnowfallできるテンプレートツールの構築に時間を使うべきか、それとも革新的な単発プロジェクトに取り組むべきか、タイムズに限らず米国や英国のニュースルームで議論が起こりました（アッシャー、2016年）。
一方、2012年にせいぜい最小限のインタラクティブだった「Snow Fall」は、2017年末の形でも最小限のインタラクティブにとどまりました。
「でも、ちょっと待って」と、かつてのデータ・ジャーナリストは宣言するかもしれません。「「Snow Fall」はデータジャーナリズムではない。ニュース・アプリの開発者が考えたトリックかもしれないが、「Snow Fall」にはデータがないのだ！」。
これこそ問題なのです。データジャーナリズムの人たちは「Snow Fall」をデータジャーナリズムだとは思っていないかもしれませんが、なぜそう思うのでしょうか？
もし、データ・ジャーナリズムがウェブの長所を生かした新しいスキルで新しい方法でストーリーを伝えることでないなら、何のためのデータ・ジャーナリズムなのでしょうか？
データジャーナリズムは、地図やグラフのためだけのものではありません。
また、データを地図やグラフにすることで、データジャーナリズムが没入型のデジタルジャーナリズムの取り組みよりも知的優位に立つことができるわけでもありません。
地図にできるものはなんでも地図にしてしまう。米国の選挙マッピングはさておき、最新の利用可能なデータを定量化し、クリックできる一貫性のある形で可視化することの倫理的な結果には批判が必要である。
データジャーナリズムは、最も日常的なものでは、単調なビジュアライゼーションとなる。
これは、データジャーナリズムプロジェクトが日常的かつ定期的な需要に向かっていることを考えると、特に当てはまります。
新しい労働統計、都市のサイクリング・データ、リサイクル率、学術研究の結果など、可視化できる（そしてクリックされやすい）データであれば、何も考えずに可視化できてしまいます。
最悪の場合、データジャーナリズムは単純化しすぎて、彼らの仕事が明らかにするはずのデータの主題から人間性を奪うことになりかねません。
ヨーロッパを流浪する移民とその流れに関する地図は、インタラクティブな矢印や性別のない人物アイコンの形をしています。
人文地理学者のポール・アダムスが主張するように、デジタル・ニュースの地図製作は難民危機をクリック可能な実体のない一連の動作に変えてしまい、未知の「難民」を共感させ、数字以上のものにするためにジャーナリズムとしてできることとは正反対である (Adams, 2017)。
また新たな社会問題や学術研究をマッピングする前に、データジャーナリストは、「私たちは何のためにマッピングし、チャート化（あるいはチャーティクル化）しているのか」と問う必要があります。
そして“Snow Fall”と移民マップの間のどこかに問題があります:データジャーナリズムは何のためにあるのか?現在は主として専門化と同型化が進んでいます。
さらにデータジャーナリズムはニュース消費者が世界を理解するのを助けるだけでなく、報道機関の収益を向上させるという企業のインセンティブが働いています。
しかし、データジャーナリズムはそれだけではありません。

The Future: How Data Journalism Can Reclaim Its Worth (and Be Fun, Too)
What is data journalism for? Data journalism needs to go back to its roots of change and revolution, of inspired hacking and experimentation, of a self-determined vision of renegades running through a tired and uninspired industry to force journalists to confront their presumed authority over knowledge, narrative and distribution. Data journalists need to own up to their hacker inspiration and hack the newsroom as they once promised to do; they need to move past a focus on profit and professionalism within their newsrooms. Reclaiming outsider status will bring us closer to the essential offering that data journalism promised: A way to think about journalism differently, a way to present journalism differently, and a way to bring new kinds of thinkers and doers into the newsroom, and beyond that, a way to reinvigorate journalism.

In the future, I imagine data journalism as unshackled from the term “data” and instead focused on the word “journalism.” Data journalists presumably have skills that the rest of the newsroom or other journalists do not: The ability to understand complicated data or guide a computer to do this for them, the ability to visualize this data in a presumably meaningful way, and the ability to code. Data journalism, however, must become what I have called interactive journalism—data journalism needs to shed its vegetable impulse of map and chart cranking as well as its scorn of technologies and skills that are not data-intensive, such as 360 video, augmented reality and animation. In my vision of the future, there will be a lot more of the BBC’s “Secret Life of the Cat” interactives and The New York Times’ “Dialect Quizzes”; there will be more projects that combine 360 video or VR with data, like Dataverse’s effort funded by the Journalism 360 immersive news initiative. There will be a lot less election mapping and cartography that illustrates the news of the day, reducing far-away casualties to clickable lines and flows. Hopefully, we will see the end of the new trend towards interactives showing live-time polling results, a new fetish of top news outlets in the United States. Rather, there will be a lot more originality, fun, and inspired breaking of what journalism is supposed to look like and what it is supposed to do. Data journalism is for accountability, but it is also for fun and for the imagination; it gains its power not just because an MP might resign or a trend line becomes clearer, but also because ordinary people see the value of returning to news organizations and to journalists because journalists fill a variety of human information needs—for orientation, for entertainment, for community, and beyond.

And to really claim superior knowledge about data, data journalists intent on rendering data knowable and understandable need to collect this data on their own—data journalism is not just for churning out new visualizations of data gathered by someone else. At best, churning out someone else’s data makes the data providers’ assumptions visible; at worst, data journalism becomes as stenographic as a press release for the data provider. Yet many data journalists do not have much interest in collecting their own data and find it outside the boundaries of their roles; as The Washington Post data editor Steven Rich explained, in a tweet, the Post “and others should not have to collect and maintain databases that are no-brainers for the government to collect. This should not be our fucking job” (Rich, 2018). At the same time, however, the gun violence statistics Rich was frustrated by having to maintain are more empowering than he realized: Embedded in government data are assumptions and decisions about what to collect that need sufficient inquiry and consideration. The data is not inert, but filled with presumptions about what facts matter. Journalists seeking to take control over the domain of facticity need to be able to explain why the facts are what they are, and, in fact, the systematic production of fact is how journalists have claimed their epistemic authority for most of modern journalism.

What data journalism is for, then, is for so much more than it is now—it can be for fun, play and experimentation. It can be for changing how stories get told and can invite new ways of thinking about them. But it also stands to play a vital role in re-establishing the case for journalism as truth-teller and fact-provider; in creating and knowing data, and being able to explain the process of observation and data collection that led to a fact. Data journalism might well become a key line of defence about how professional journalists can and do gather facts better than any other occupation, institution or ordinary person ever could.

Works Cited

Adams, P. (2017). Migration maps with the news: Guidelines for ethical visualization of mobile populations. Journalism Studies, 19(1), 1–21.doi.org/10.1080/1461670X.2017.1375387

Lewis, N. P., & Waters, S. (2018). Data journalism and the challenge of shoe-leather epistemologies. Digital Journalism, 6(6), 719–736. doi.org/10.1080/21670811.2017.1377093

Lewis, S. C., & Usher, N. (2013). Open source and journalism: Toward new frameworks for imagining news innovation. Media, Culture & Society, 35(5), 602–619. doi.org/10.1177/0163443713485494

Lewis, S. C., & Usher, N. (2016). Trading zones, boundary objects, and the pursuit of news innovation: A case study of journalists and programmers. Convergence, 22(5), 543–560. https://doi.org/10.1177/135485...

Loosen, W., Reimer, J., & De Silva-Schmidt, F. (2020). Data-driven reporting: An on-going (r)evolution? An analysis of projects nominated for the Data Journalism Awards 2013–2016. Journalism, 21(9), 1246–1263. doi.org/10.1177/1464884917735691

Rich, S. (2018, February 15). The @washingtonpost and others should not have to collect and maintain databases that are no-brainers for the government to collect. This should not be our fucking job. Twitter. twitter.com/dataeditor/status/964160884754059264

Stoiber, C., Aigner, W., & Rind, A. (2015). Survey on visualizing dynamic, weighted, and directed graphs in the context of data-driven journalism. In Proceedings of the International Summer School on Visual Computing (pp. 49–58).

Usher, N. (2016). Interactive journalism: Hackers, data, and code. University of Illinois Press.

Young, M. L., Hermida, A., & Fulda, J. (2018). What makes for great data journalism? A content analysis of Data Journalism Awards finalists 2012–2015. Journalism Practice, 12(1), 115–135. doi.org/10.1080/17512786.2016.1270171


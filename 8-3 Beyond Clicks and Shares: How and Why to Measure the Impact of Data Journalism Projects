クリックとシェアを超えて:データジャーナリズムのプロジェクトのインパクトを測定する方法と意義
Written by: Lindsay Green-Barber
概要
本章では、データジャーナリズムが個人、ネットワーク、制度にインパクトを与えるユニークな立場にあることを論じ，そのインパクトを測定するための戦略を提案します。
キーワード：インパクト、社会科学、インパクト測定、アナリティクス、データジャーナリズム、オーディエンス・エンゲージメント
ジャーナリズムと影響力
多くのジャーナリストはジャーナリズムの影響力という考え方に難色を示しますが、実際には、現代のジャーナリズムは職業として、影響力という基盤の上に成り立っているのです。私たちが市民として活動し、権力者の責任を追及できるように、一般大衆に情報を提供することです。ジャーナリストは、自分たちの仕事がもたらすポジティブな（あるいはネガティブな）影響について考え、話し、戦略を立て、測定することは、ジャーナリズムから提言活動へのレッドラインを越えすぎてしまうのではないかと心配していますが、専門家やコメンテーターも同様に、「フェイクニュース」、誤報、党派報道が個人、社会、民主主義に及ぼす悪影響について多くのコラムインチとピクセルを使って悲痛に訴えてきています。言い換えれば、ジャーナリストは自分たちの仕事が及ぼす影響について語ることを避けたい一方で、"フェイクニュース "が社会的、政治的、文化的に深刻な影響を及ぼすことは認識しているのです。
しかも、19世紀後半から20世紀初頭にかけてジャーナリズムが専門化する以前は、ジャーナリズムは影響力のある実践であり、政党に支えられ、政党を支持しその候補者を確実に当選させるという明確な目標を持って制作されていました（Pitt & Green-Barber, 2017）。したがって、歴史的な観点から見ると、ジャーナリズムの専門化と（中立性の）神話の受け入れは、実は極めて新しいものである（Groseclose & Milyo, 2005; Hamilton, 2004）。そして、ジャーナリズムが「中立性」を追求したのは、規範的な決定ではなく、経済モデルの変化と、収益を上げるために可能な限り多くの読者にアピールする必要性によるものであった（Hamilton, 2004）。
米国や西ヨーロッパでは、報道業界のビジネスモデルとメディアに対する国民の信頼の欠如が同時に、かつ密接に関連していることを考えると、ジャーナリズムがその影響を認識することから目を背けてきたことは、よく言っても責任放棄、悪く言えば失敗だったかもしれません。
しかし、希望の兆しもあります。近年、一部の報道機関が、自分たちが社会に影響を与える存在であることを認め始めているのです。
使命感にあふれた慈善財団や個人の支援を受けた非営利のメディアが急増し、影響力（を把握する）実験のためのペトリ皿が作られたのです。
多くの商業メディアも、自分たちの仕事がもたらすポジティブなインパクトを視聴者に伝えることは、信頼とロイヤリティを築くための戦略であり、うまくいけば収益の増加につながると見なしています。
例えば、2017年、ワシントン・ポストは「Democracy Dies in Darkness」をマストヘッドに加え、政治システムにおけるその役割を受け入れました（そして宣伝しました）。
また、CNNはウェブサイトに「Impact Your World」セクションを設け、世界の出来事、その報道、「インパクト」のあるストーリー、視聴者がハッシュタグキャンペーンから寄付まで、行動を起こすための経路をつなげました。

Media organizations have also begun to try new strategies to maximize the positive impact of their work, as well as to use research methods and metrics different from those used for advertising to understand the effectiveness of these strategies. While, in some cases, digital metrics can be useful proxies for impact measurement, advertising metrics like unique page views or even more advanced analytics like time spent on a page are meant to measure the reach of content without consideration of the effects of this content on an individual.

I would like to propose a framework for media impact that is a change in the status quo as a result of an intervention and that includes four types of impact: On individuals, on networks, on institutions and on public discourse. These types of impact are interrelated. For example, as journalism often assumes, reporting can increase individuals’ level of knowledge about an issue, resulting in them voting in a particular way and ultimately affecting institutions. Or, a report may have immediate effects on institutions, such as a firing or a restructuring, which then trickles down to impact individuals. However, impact that is catalyzed by journalism often takes time and involves complex social processes.

Different types of journalism are better equipped for different types of impact. For example, James T. Hamilton shows that investigative reporting can save institutions money by uncovering malfeasance, corruption or wrongdoing and spurring change. And documentary film has proven to be particularly effective in generating new and/or strengthened advocacy networks to promote change (Green-Barber, 2014).

The remainder of this chapter explores the relationship between data journalism and impact, demonstrating how data journalism can contribute to various types of social change. It then suggests methods for how data journalism’s effectiveness might be measured, and what journalists and news organizations can do with this information.

Why Data Journalism
While journalists employ data journalism for many reasons, there are two that come to the fore: First, to provide credible evidence to support claims made in storytelling; and second, to present information to audiences as data, rather than text-based narrative. The practice of data journalism is built on a foundational value judgement that data is credible, and, by extension, that a journalistic product that includes data reporting is credible—and potentially more so than it would be without.

Data reporting that is used to communicate information as static numbers, data, charts, graphs or other visuals is similar to other journalistic formats (i.e., text, video, audio) in that it is essentially a linear form of communicating selected information to an audience. Data reporting that is made available to audiences through a news interactive is a unique form of storytelling in that it assumes an audience member will interact with the data, ask their own questions and search for answers in the data at hand. Thus, the “story” depends upon the user as much as it does on the journalism.

Even this rough-hewn version of data journalism implicates all four types of impact.

Individuals
Data journalism tends to focus on individual audience members as the potential unit for change, providing audiences with credible information so that they may become more knowledgeable and, by extension, make more informed decisions. And while data journalism as a scaffolding for traditional, linear storytelling increases audience trust in the content, news or data interactives provide the greatest potential for data journalism to have an impact at the level of individuals.

With a data interactive, that is, a “big interactive database that tells a news story,” a user can generate their own question and query the data to look for answers (Klein, 2012). Media companies often assume that data interactives will allow audiences to do deep dives and explore data, find relevant information, and tell stories. In an analysis of data interactives by one news organization, the author of this chapter found that the most successful data apps, meaning those that were highly trafficked and deeply explored, were part of a full editorial package that included other content, offered the ability to look up geographically local or relevant data, had a high degree of interactivity, were aesthetically pleasing and well-designed, and loaded quickly (Green-Barber, 2015b).

ProPublica’s Dollars for Docs is a classic example of data journalism in that it accesses significant amounts of data, in this case about pharmaceutical and medical device companies’ payments to doctors, structures the data, and presents it to audiences as an interactive database with the goal to inspire individuals to conduct their own research and possibly take action.2 The project instructs audiences to “use this tool” to search for payments to their doctors, and, in a sidebar, says, “Patients, Take Action. We want to know how you’ve used or might use this information in your day to day lives. Have you talked to your doctor? Do you plan to? Tell us.”3

Networks
Data journalism provides credible information that can be used by networks (formal and/or informal) to strengthen their positions and work. For example, advocacy organizations often use data reporting to bolster their claims in public appeals or in legal proceedings, especially in cases where the data is not publicly available. Journalism’s practice of requesting access to data that is not available in the public realm, analyzing this data and publishing the findings, absorbs costs that would otherwise be insurmountable for individuals or networks (Hamilton, 2016).

Institutions
Data journalism can generate reporting that institutions work hard to keep hidden, as they are evidence of corruption, malfeasance, wrongdoing and/or incompetence. When this information comes to light, there is pressure on institutions to reform—resulting from the threats associated with elections on politicians, or market forces on publicly held companies.

For example, the International Consortium of Investigative Journalists’ Panama Papers collaborative investigation analyzed more than 11.5 million records to uncover “politicians from more than 50 countries connected to offshore companies in 21 tax havens.”4 This investigation led to the resignation of politicians, such as Iceland’s prime minister, Sigmundur Gunnlaugsson, investigations of others, like Pakistan’s former prime minister, Nawaz Sharif (who was sentenced to ten years in jail in 2018), and countless other institutional responses.

Public discourse
Because data journalism can often be broken down into smaller parts, whether geographically, demographically or by other factors, the data can be used to tell different stories by different media. In this way, data journalism can be localized to generate a shift in public conversation about issues across geographic locations, demographic groups or other social boundaries.

The Center for Investigative Reporting has published national interactive data sets about the US Department of Veterans Affairs (VA), one with average wait times for veterans trying to access medical care at VA hospitals, and a second with the number of opiates being prescribed to veterans by VA systems. In both cases, local journalism organizations used the data sets as the baseline to do local reporting about the issues.

So, How Can Data Journalists Strategize for Impact?
You have done the hard work: You got access to data, you crunched the numbers, you structured the data and you have an important story to tell. Now what?

A high-impact strategy for data journalism might follow the following five steps:

Set goals. What might happen as a result of your project? Who or what has the power and/or incentive to address any wrongdoing? Who should have access to the information you are bringing to light? Ask yourself these questions to decide what type or types of impact are reasonable for your project.

Content. Once you have goals for your project, identify the important target audiences for the work. What source of news and information do these audiences trust? How might they best access the information? Do they need an interactive, or will a linear story be more effective?

Engagement. How will you and your news organization engage with audiences, and how will audiences engage with your work? For example, if you have identified a news organization other than your own as a trusted source of information for a target audience, collaborate. If your data interactive has important information for an NGO community, hold a webinar explaining how to use it.

Strategic research. Depending upon your goals and content and engagement plans, select the appropriate research methods and/or indicators in order to track progress and understand what is working and what is not working. While media often refer to “measuring” the impact of their work, I prefer the term “strategic research,” as both qualitative and quantitative research methods should be considered. The sooner you can identify research methods and indicators, the better your information will be. (The subsequent section discusses measurement options in greater depth.)

Repeat. You have invested time and resources in your data journalism reporting, content, engagement and measurement. What worked? What will you change next time? What questions are still outstanding? Share these learnings with your team and the f ield to push the next project further ahead.

How Do We “Measure” the Impact of Our Work?
As alluded to earlier, media impact research has been dominated by advertising metrics. However, ad metrics, like page views, time on page and bounce rate are potential proxies for some impact. They are meant to measure the total exposure of content to individuals without concern for their opinions about the issues, whether or not they have learned new information, or their intent to take action based upon the content. When considering the impact of content on individuals, networks, institutions and public discourse, however, there are other innovative qualitative and quantitative methods that can be used to better understand success and failure in this area. This section explores a handful of promising research methods for understanding the impact of data journalism.

Analytics. Media metrics can be used as proxies for desired outcomes, such as increased awareness or increased knowledge. However, media companies should be intentional and cautious when attributing change to analytics. For example, if a data journalism project has as its goal to spur institutional change, unique page views are not an appropriate metric of success; mentions of the data by public officials in documents would be a better indicator.

Experimental research. Experimental research creates constant conditions under which the effects of an intervention can be tested. The Center for Media Engagement at the University of Texas at Austin has conducted fascinating experimental research about the effects of news homepage layout on audience recall and affect, and of solutions-oriented reporting on audience affect for news organizations. Technology companies are constantly testing the effects of different interactive elements on users. Journalism organizations can do the same to better understand the effects of data interactives on users, whether in partnership with universities or by working directly with researchers in-house from areas like marketing, business development and audience engagement.

Surveys. Surveys, while not the most leading-edge research method, are a proven way to gather information from individuals about changes in interest, knowledge, opinion and action. Organizations can be creative with survey design, making use of technology that allows for things like return visit-triggered pop-ups or tracking newsletter click-through to generate a survey pool of potential respondents.

Content analysis. Content analysis is a research method used to determine changes in discourse, over time. This method can be employed to any text-based corpus, making it extremely flexible. For example, when an organization produces content with the goal of influencing national public discourse, it could conduct a post-project content analysis on the top ten national newspapers to determine the influence of its stories. If the goal is to influence state legislature, an organization can use post-project content analysis on publicly available legislative agendas (Green-Barber, 2015a). Or, if the goal is to make data available to advocacy networks, post-project content analysis could be used to analyze an organization’s newsletters.

Content analysis can be conducted in at least three ways. At the most basic level, a news organization can search for a project’s citations in order to document where and when it has been cited. For example, many reporters create Google News Alerts using a keyword from their reporting, together with their surname, in order to determine in what other outlets a project is picked up. This is not methodologically sound, but it provides interesting information and can be used to do a gut check about impact. This process may also generate additional questions about a project’s impact that are worth a deeper dive. Many organizations use news clipping services like Google News Alerts or Meltwater for this purpose.

Rigorous content analysis would identify key words, data and/or phrases in a project, then analyze their prevalence pre- and post-publication in a finite corpus of text to document change. Computational text analysis goes a step further and infers shifts in discourse by advanced counting and analysis techniques. These more rigorous content analysis methods likely require a news organization to partner with trained researchers.

Looking Ahead: Why Journalists Should Care about the Impact of Data Journalism
To stay relevant, journalism must not only accept that it has an impact on society, but embrace that fact. By working to understand the ecosystem of change in which journalism functions, and its specific role within this system, the industry can work to maximize its positive impact and demonstrate its value to audiences.

Data journalists, with their understanding of the value and importance of both quantitative and qualitative data, are well positioned for this endeavour. By articulating the goals of data journalism projects, developing creative audience engagement and distribution strategies, and building sophisticated methods for measuring success into these projects, reporters can lead this movement from within.

Footnotes

1. edition.cnn.com/specials/impact-your-world

2. projects.propublica.org/docdollars/

3. propublica.forms.fm/was-the-dollars-for-docs-information-helpful-tell-us-how-you-will-use-it/forms/2249

4. www.icij.org/investigations/panama-papers/

Works cited

Green-Barber, L. (2014). Waves of change: The case of rape in the fields. The Center for Investigative Reporting. www.documentcloud.org/documents/1278731-waves-of-change-the-case-of-rape-in-the-fields.html

Green-Barber, L. (2015a). Changing the conversation: The VA backlog. The Center for Investigative Reporting. s3.amazonaws.com/uploads-cironline-org/uploaded/uploads/VA+Backlog+White+Paper+11.10.14.pdf

Green-Barber, L. (2015b). What makes a news interactive successful? Preliminary lessons from the Center for Investigative Reporting. The Center for Investigative Reporting. s3-us-west-2.amazonaws.com/revealnews.org/uploads/CIR+News+Interactives+White+Paper.pdf

Groseclose, T., & Milyo, J. (2005). A measure of media bias. The Quarterly Journal of Economics, 120(4), 1191–1237. doi.org/10.1162/003355305775097542

Hamilton, J. T. (2004). All the news that’s fit to sell: How the market transforms information into news. Princeton University Press.

Hamilton, J. T. (2016). Democracy’s detectives: The economics of investigative journalism. Harvard University Press.

Klein, S. (2012). News apps at ProPublica. In J. Gray, L. Chambers, & L. Bounegru (Eds.), The data journalism handbook: How journalists can use data to improve the news (pp. 185‒186). O’Reilly Media.

Pitt, F., & Green-Barber, L. (2017). The case for media impact: A case study of ICIJ’s radical collaboration strategy. Tow Center for Digital Journalism. doi.org/10.7916/D85Q532V


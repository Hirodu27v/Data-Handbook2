注目されるアルゴリズム：シュピーゲルオンラインでの共同調査
Written by: Christina Elmer
アルゴリズムの透明性を求める声は、ドイツでは新しいものではありません。
2012年には、デア・シュピーゲルのコラムニストのサシャ・ロボが、Googleに、たとえ損害を受けるとしても検索アルゴリズムの仕組みを開示するよう求めました（Lobo, 2012）。
ドイツで起きた著名な事件が示したように、Googleはオートコンプリート機能などを通じて、私たちの世界の見方を形成することができます。
前連邦大統領の妻（ベティーナ・ウルフ）は、自分の名前を検索したときにオートコンプリート機能で問題のある表示が提案されたとして、Googleを提訴しました。
2年後、ドイツの法相はこの訴えを繰り返し、首相は2016年にこれを再び蒸し返しました:メルケル首相は「アルゴリズムはより透明であるべきである」と求めたのです（Kartell, 2014; Reinbold, 2016）。
ここ数年、シュピーゲルはアルゴリズムの説明責任について議論してきましたが、当初は報道の対象としてのみで、独自の調査や分析プロジェクトはありませんでした。
ドイツのメディアが米国のメディアよりも遅れてこの分野の実験を始めた理由は、主に2つあると思われます。
第一に、ドイツのジャーナリストには、自由に使える強力な情報公開の権利や手段がないこと。第二に、データ・ジャーナリズムには、米国のような長い伝統がありません。
シュピーゲルは16年に独自のデータジャーナリズム部門を設けたばかりですが、徐々に、しかし着実にこの分野を拡大しています。
もちろん、（経営）リソースの少ないニュースルームでも、組織やフリーランサーとの協力などを通じて、この分野で活躍することは可能です。
私たちの場合も、これまでに取り組んできたアルゴリズムによる説明責任報道のプロジェクトは、すべてこのような方法で生まれたものです。そこで本章では、共同作業とそこから得られた教訓に焦点を当てます。
Google、Facebook、Schufa:三つのプロジェクトの概要
私たち編集部は、（外部との）協力を中心にアルゴリズムの調査をしています。2017年の連邦選挙に向けて、私たちはNGO「AlgorithmWatch」と協力して、Googleの検索結果のパーソナライズについての知見を得ました。
ユーザーには、あらかじめ定義された検索を定期的に実行するプラグインを自分のコンピューターにインストールしてもらいました。合計で約4,400人の参加者が約600万件の検索結果を提供してくれたため、少なくともGoogleと調査対象地域に関しては、フィルターバブル理論に疑問を投げかける分析データを得ることができたのです。
このプロジェクトでは、AlgorithmWatchの共同研究者がデア・シュピーゲルにアプローチしてきました。必要なデータをクラウドソーシングするために、大きなリーチを持つメディアパートナーを探していたのです。
取材はインターネットやテクノロジー関連の話題を扱う部門が担当しましたが、データジャーナリズム部門は、取材の計画や方法論の評価をサポートしました。
さらに、法的に問題のない方法でプロジェクトを遂行するためには、法務部門のバックアップが不可欠でした。例えば、データ保護の問題は、報道の中で明確にされなければならず、プロジェクトに参加したすべての人が十分に理解できるようにしなければなりません。
並行して、シュピーゲルはプロパブリカとともに、選挙前の数ヶ月間にドイツでAdCollectorを展開しました（Angwin & Larson, 2017）。
このプロジェクトは、ドイツの政党がFacebookユーザーをターゲットに広告を出す様子を明らかにすることを目的としたものです。
あるプラグインを用いて、ユーザーが自分のストリームで目にする政治広告を収集し、どんな広告がユーザーに表示されないのかを明らかにしました。
南ドイツ新聞やターゲスシャウなど他のドイツのメディアとも協力しました。
この場合、公共の利益に資するため、できるだけ多くの人々に情報を届ける必要がありました。結果を記事として発表することもできましたが、私たちが最も重視したのは透明性です。2週間後には、約600の政治広告が収集され、公開されました。
プロパブリカのジュリア・アングウィンとジェフ・ラーソンはハンブルグで開催されたドイツの調査報道ジャーナリスト協会Netzwerk Rechercheの年次大会で，アルゴリズムの説明責任報道に関するセッションを行い，コラボレーションのアイデアを紹介しました。
このアイデアは、シュピーゲルの報道部門の複数の部署から集まった技術・方法論の専門家と協力して、一から練り上げられたものです。
また、以前からのパートナーである非営利団体AlgorithmWatchとの交流は、法的背景に光を当て、それを研究に盛り込むために、私たちにとって非常に貴重なものとなりました。
大会後は、定期的に電話会議を行い、さらにアイデアを広げていきました。ドイツの他のメディアのパートナーも、後から参加してくれました。
2018年、デア・シュピーゲルは、ドイツの極めて強力なアルゴリズム、心情情報機関Schufaを調査する一大プロジェクトに携わりました。
このレポートは、民間人の信用力を評価するために使用されます。このレポートは、誰かが請求書を支払ったり、家賃やローンを負担できる確率を示す必要があります。
そのため、個人の私生活に多大な影響を与え、社会全体にも悪影響を及ぼす可能性があります。
例えば、個人に関して利用できるデータの量によっては、スコアが社会的な差別や不平等な扱いを助長することも考えられます。
誤ったデータや取り違えは、個人にとって致命的となる可能性があります。アルゴリズムの基礎となるスコアリングは透明ではありません。どのデータがどのような重み付けで考慮されるのかは不明です。また、影響を受ける人は、そのプロセスを知らないことが多いのです。
このような状況から，ドイツではSchufaが議論の対象となっており、OpenSCHUFAのようなプロジェクトはアルゴリズムの説明責任に関する公共の討論に不可欠なのです。
このプロジェクトは、NGOであるOpen Knowledge Foundation（OKFN）とAlgorithmWatchが中心となって進められました。シュピーゲルは、バイエルン放送とともに提携パートナーを務めました。
このプロジェクトのアイデアは、複数の関係者がほぼ同時に思いついたものでした。NGOのAlgorithmWatchとOKFN、そしてバイエルン放送のデータジャーナリズムチームがプロジェクトを成功させた後、シュピーゲルが初の会合に加わったのです。
この組み合わせは、特別な課題を提示しました。両メディアチームにとっては、特にクラウドファンディングのプロセスからの独立性を確保するため、NGOとは別に活動することが重要でした。
そのため、関係者間での話し合いはあったものの、正式なパートナーシップや共同でのデータ評価はできませんでした。この例は、特にこのような公共性の高いテーマにおいて、ジャーナリストが自らの自律性について考えることがいかに重要かを示しています。
OpenSCHUFAを知ってもらうことは、このプロジェクトの中心的な成功要因の一つでした。まず、データを収集するために必要なインフラをクラウドファンディングを利用して構築しました。
結果は、匿名化された形で、年間を通じてパートナーが共同で評価しました。その背後にある中心的な疑問は、Schufaアルゴリズムは特定の集団を差別し、社会の不平等を増大させるのかということです。
結果を見ると、そのようになっています。このスコアは、高齢者や女性、居住地の変更頻度が低い人を優遇していることがわかりました。
スコア内のアルゴリズムのバージョンが異なると、同じ属性の人でも結果が異なるという、これまで知られていなかったタイプの差別が発見されました。
これらの成果は、多くのボランティアや支援者の参加がなければ実現しませんでした。クラウドファンディングのキャンペーンはほぼ成功し、こうした枠組みの中でソフトウェアの資金を確保することができました。
また、その後のクラウドソーシングでは、約2,800人の方から個人信用情報が寄せられました。このサンプルは、もちろん代表的なものではありませんが、今回の調査結果を明らかにするのに十分な多様性を持っています。
影響と成功の指標

FacebookとGoogleの調査は、どちらも結果としては地味だったものの、私たちの仮説を裏付けるものでした。
政党はFacebookのターゲティングオプションをほとんど利用していないようですし、よく言われるGoogleのフィルターバブルはドイツでのクラウドソーシング実験では見つかりませんでした。
しかし、私たちにとってこれらのプロジェクトの価値は、社会におけるアルゴリズムの機能性とリスクに関する読者のリテラシーを高めることにありました。
記事の到達度は、私たちがこのテーマをより広く知らしめることに成功したことを示す指標となりました。Schufaプロジェクトの開始時に掲載した記事は、多くの読者（約33万5000人）に読まれました。
さらに、このトピックは公共の場で広く議論され、多くのメディアや会議で取り上げられました。
ドイツの消費者保護相は、信用スコアリングの透明性向上を求め、「全国民は、自分の信用度を計算する際にどのような特徴が含まれているのか、またそれらがどのように重み付けされているのかを知る権利を持たなければなりません」と訴えました。
日常生活への影響はどうでしょう？最初のステップとして、私たちはこのテーマを一般の人々の意識に定着させることが重要でした。
これまでのところ、政治家がより広い社会的影響を持つアルゴリズムに対処するまったく斬新な方法は見つかっていません。
とはいえ、アルゴリズムの説明責任報告というトピックは、私たちにとって非常に重要です。なぜなら、ヨーロッパでは、社会におけるアルゴリズムの問題を議論し、それにどう対処したいかを形作る余地がまだあるからです。
市民が社会におけるアルゴリズムの未来を理解し、形作ることができるように、必要な知識を提供することは、私たちジャーナリストの責務です。
可能な限り、アルゴリズムとその影響を透明化し、リスクを特定し、責任者と対決することで、監視役としての役割も担っています。
そのためには、競合他社や他の分野の人々と、通常では考えられないような協力関係を築かなければなりません。私たちは、このような協力関係が、最終的にこの分野の法律や透明性の基準に対する圧力を高めることを期待しています。
アルゴリズムの説明責任の調査には、より多くの努力と資源が投入されるべきであり、「The Markup」はこの分野で非常にエキサイティングな調査結果を発表しています。
アルゴリズムの規制にはまだ行動の余地があることもあり、さらなる調査が求められています。アルゴリズムによる説明責任報道は、ここ数年で発展し始めたばかりです。デジタル化が進む世界の課題に対応するためには、急速に成長しなければなりません。
共同調査の組織化

共同調査を実行するには、新しい、あるいはニュースルームであまり使われていないスキルが必要です。これには、大規模なデータセットの分析やプログラミングだけでなく、プロジェクトの管理も含まれます。後者は見落とされがちなので、ここでは、私たちがこれまでに行ってきた仕事の具体例を挙げながら、詳しく説明します。
多様な人々からなる集団での共同作業は、能力やリソースの共有を容易にするだけでなく、役割を明確に定義することができます。
シュピーゲルは、これらの協働においては、メディア・パートナーとしてプロジェクト自体にはあまり深く関与せず、中立的なコメンテーターとして関わりました。
これにより、編集者は独立性を保つことができ、読者の信頼を得ることができました。編集者たちは、プロジェクト内の報道にも品質基準を適用し続けました。
たとえば、報道の対象となった人には、告発についてコメントする機会を常に与えることにしています。
このようなメカニズムは、NGOと比較して活動を遅らせることになるかもしれません。しかし同時に、読者に十分な情報を提供し、長期的には社会的な議論を豊かにすることができるのです。
アルゴリズムの説明責任の共同研究では，これらの役割について事前に合意しておくことが重要な成功基準になることがわかっています。
また、早い段階で共通のタイムラインを作成し、さまざまなチャンネルでプロジェクトを発表する際の言語ルールを定めておく必要があります。
結局のところ、明確な役割分担は、それが一貫して伝えられて初めて機能するものだからです。
これには、例えば、プロジェクトにおけるさまざまなパートナーの役割に関する明確な用語や、利益相反が発生した場合の免責事項の調整などが含まれます。

Behind the scenes, project management methods should be used prudently, project goals should be set clearly and available resources have to be discussed. Coordinators should help with the overall communication and thus give the participating editors the space they need for their investigations. To keep everyone up to date, information channels should be kept as simple as possible, especially around the launch of major project stages.

Regarding editorial planning, the three subject areas were challenging. Although in general relevance and news value were never questioned, special stories were needed to reach a broad readership. Often, these stories focused on the personal effects of the algorithms examined. For example, incorrectly assigned Schufa data made it difficult for a colleague from the Der Spiegel editorial team to obtain a contract with an Internet provider. His experience report impressively showed what effects the Schufa algorithm can have on a personal level and thus connected with the reality of our audience’s lives (Seibt, 2018).

Thus, we tailored the scope of our reporting to the interests of our audience as far as possible. Of course, the data journalists involved were also very interested in the functioning of the algorithms under investigation—an interest that is extremely useful for research purposes. However, only if these details have a relevant influence on the results of the algorithms can they become the subject of reporting—and only if they are narrated in a way that is accessible for our readers.

Internally in the editorial office, support for all three projects was very high. Nevertheless, it was not easy to free up resources for day-to-day reporting in the daily routine of a news-driven editorial team—especially when the results of our investigations were not always spectacular.

Lessons Learned

By way of conclusion, I summarize what we have learned from these projects.

Collaborate where possible. Good algorithmic accountability investigations are only possible by joining forces with others and creating teams with diverse skill sets. This is also important given both the scarcity of resources and legal restrictions that most journalists have to cope with. But since these projects bring together actors from different fields, it is crucial to discuss beforehand the underlying relevance criteria, requirements and capabilities.

Define your goals systematically. Raising awareness of the operating principles of algorithms can be a first strong goal in such projects. Of course, projects should also try to achieve as much transparency as possible. At best we would check whether algorithms have a discriminatory effect—but project partners should bear in mind that this is a more challenging goal to attain, one that requires extensive data sets and resources.

Exercise caution in project implementation. Depending on the workload and the day-to-day pressure of the journalists involved, you might even need a project manager. Be aware that the project timeline may sometimes conflict with reporting requirements. Take this into account in communicating with other partners and, if possible, prepare alternatives for such cases.

Invest in research design. To set up a meaningful design that produces useful data, you might need specialized partners. Close alliances with scientists from computer science, mathematics and related disciplines are particularly helpful for investigating some of the more technical aspects of algorithms. Furthermore, it may also be useful to cooperate with social and cultural researchers to gain a deeper understanding of classifications and norms that are implemented in them.

Protect user data. Data donations from users may be useful to investigate algorithms. In such crowdsourcing projects legal support is indispensable in order to ensure data protection and to take into account the requirements of the national laws and regulations. If your company has a data protection officer, involve them in the project early on.

Footnotes

1. algorithmwatch.org/de/filterblase-geplatzt-kaum-raum-fuer-personalisierung-bei-google-suchen-zur-bundestagswahl-2017// (German language)

2. www.openschufa.de (German language)

3. www.startnext.com/open... (German language)

4. The majority of these, however, came to the article via internal channels like our homepage. This was different in the case of another article, the field report featuring the author’s personal story, which was read by around 220,000 people. A fifth of them reached the article via social media channels, which is well above the average. So it seems that we were able to reach new target groups with this topic.

Works Cited

Angwin, J., & Larson, J. (2017, September 7). Help us monitor political ads online. Pro- Publica. www.propublica.org/article/help-us-monitor-political-ads-online

Kartell, S. vor. (2014, September 16). Maas hätte gerne, dass Google geheime Such- formel offenlegt. Der Spiegel. www.spiegel.de/wirtschaft/unternehmen/

Lobo, S. (2012, September 11). Was Bettina Wulff mit Mettigeln verbindet. Der Spiegel. www.spiegel.de/netzwelt/netzpolitik/google-suchvorschlaege- was-bettina-wulff-mit-mettigeln-verbindet-a-855097.html

Reinbold, F. (2016, October 26). Warum Merkel an die Algorithmen will. Der Spiegel. www.spiegel.de/netzwelt/netzpolitik/angela-merkel-warum-die-kanzlerin-an-die-algorithmen-von-facebook-will-a-1118365.html

Seibt, P. (2018, March 9). Wie ich bei der Schufa zum “deutlich erhöhten Risiko” wurde. Der Spiegel. www.spiegel.de/wirtschaft/service/schufa-wie-ich- zum-deutlich-erhoehten-risiko-wurde-a-1193506.html

データジャーナリズムの系譜

Written by: C.W. Anderson
なぜ、データジャーナリズムの歴史に関心を持つべきなのでしょう。
「歴史」は多くの人にとってかなり学術的で抽象的な話題で、仕事に追われる現役のデータ・ジャーナリストにとっては特に縁遠いものかもしれません。
ジャーナリストは、厳しい締め切りの中で、できるだけ多くの読者に複雑な情報を素早く分かりやすく伝えることを目標に仕事をしているので、自省に時間を費やすことを嫌うのは当然でしょう。
しかし、データジャーナリズムやコンピュータ支援報道の実践や概念に関しては、歴史的思考の忌避が、質の高いジャーナリズムの生産を妨げることがあります。
データジャーナリズムは、今日の世界で最も強力なジャーナリズムの集団的センス・メイキングの形態かもしれません。
少なくとも、最もポジティブで実証的なジャーナリズムの形態でしょう。
この力（データジャーナリズムのモデルの修辞的な力とともに、質の高いジャーナリズムを生み出すデータジャーナリズムの能力）、積極性（ほとんどのデータジャーナリストは、自分たちの特定のサブフィールドの将来に大きな期待を持ち、それが上昇傾向にあると確信している）、実証性（データ記者は、世界に関する実際の証明できる事実を捉える、方法に基づいた調査の能力に対する強い信者）により、私が経験的に自信に満ちた職業と呼ぶものが生み出されています。
この自己肯定感の結果、データジャーナリズムは常に世界を改善し、向上させているという（進歩主義的）ホイッグ史観のような思い込みも生まれかねません。
こうした態度は、傲慢さと批判的な自己反省の欠如を招き、ジャーナリズムを、その時間を費やして責任を追及している機関と同じようなものにしてしまう可能性があるのです。
この章では、歴史にもっと注意を向けることで、データ・ジャーナリズムの日々の活動を実際に改善できることを主張したいと思います。
自分たちのプロセスや実践には歴史があることを理解することで、データ・ジャーナリストは、現在の物事がかつてそうでなかったかもしれず、別の方法で行われる可能性があるという事実を受け入れられるのです。
特に、データ・ジャーナリストは、実証的な作業において不確実性を創造的に表現する方法について、より深く考えることができるかもしれません。
また、単に事実上の証拠を述べるだけでなく、さまざまな政治的感性や説得力のある読者を引き込むためのテクニックを考えるかもしれません。
つまり、科学技術研究者で歴史家のキャサリン・ディグナツィオとローレン・クラインが「フェミニスト・データ・ビジュアライゼーション」と呼ぶ、二項対立を再考し、多元性を受け入れ、権力を検証し、文脈を考慮するような形に自らを開放することができるだろう（ディグナツィオとクライン、2020年、本書のディグナツィオの章も参照のこと）。
これらの変化を達成するために、データジャーナリズムは自らの力と自信の性質があるゆえに、ジャーナリズムの実践の多くの形態よりもいっそう確かにこの強力な歴史感覚を教え込むべきである。
私は、ミシェル・フーコーによって開拓され、科学の歴史家や科学技術研究者によって受け入れられた概念の発展への系譜学的アプローチほど、自己再帰性を導く能力を備えた歴史の形式はないと主張したい。
フーコーが定義した「系譜学」は、ニーチェの著作を参考にしながら、制度や概念の時間的変遷を研究するユニークなアプローチであり、歴史とは異なります。
系譜学的分析は、過去の慣習や思想の切れ目のない単一の起源を探すものではないし、概念が昨日から今日まで切れ目のない進化的なラインでどのように発展してきたかを理解しようとするものでもないのです。
むしろ、現在からみて過去がどうだったかということよりも、不連続性や予期せぬ変化に注目します。
ニーチェは、フーコーが引用した『道徳の系譜』の一節で、次のように指摘します。
ある物事、慣習、器官の「発展」は、単一の目標に向かう進歩とは何の関係もなく、ましてや力や資源の最小限の消費で到達する論理的かつ最短の進歩でもない。
むしろそれは、その物に起こる多かれ少なかれ深遠で、多かれ少なかれ相互に独立した圧倒のプロセスの連続であり、その都度その圧倒に対して生じる抵抗、防御と反作用の目的で試みられた形態の変化、および成功した対抗措置の結果なのである。
形は流動的であるが、「意味」はさらに流動的である。(Foucault, 1980)
「データジャーナリズムの系譜」は、データ・ジャーナリズムが、その創作者や実践者が予想しなかった方法で、あるいは彼らの願望に反する方法で進化してきたことを明らかにします。
歴史が私たちを驚かせ、時には予期せぬ方向へ導いてくれるのを目の当たりにしているのです。
このアプローチは、先に述べたように、現代の現役データジャーナリストに特に有効なものです。自分たちは由緒ある伝統の中で働いているのではなく、むしろ、根本的に偶発的な方法で、自分たちの手で作り上げているのだということを理解する助けになると思うのです。
そしてそれは、批判的な自己反省を促すものであり、現役のデータ・ジャーナリストやレポーターの（理解できる、しばしばそれに値する）自負心を和らげるのに役立つかもしれないのです。
私は拙著『確かさの使徒たち：データジャーナリズムと疑念の政治学』で、このような系譜の記述を試みています。
この後のページでは、この本の主な発見をいくつかまとめ、その教訓が現代に役立つかもしれない方法を論じたいと思います。
最後に、ジャーナリズム、特にデータ化された類のジャーナリズムは、知らないことをよりうまく示すことができるし、そうすべきであり、不確実性に向けたこれらのジェスチャーは、データジャーナリズムの起源を、もしそれが表象化されたものであるというよりは、非合法な権力への批判に置くことを尊重するものであると主張したい。
データジャーナリズムの変遷：1910年代、1960年代、2010年代
より良いジャーナリズムを生み出すために、数値の紙文書、データの可視化、チャートやグラフといった他の形式の定量化された情報とともに、データを活用できるか。
そして、そのジャーナリズムは、国民がよりよい政治的選択をするために、どのように役立つのだろうか。
これらの疑問が、「確かさの使徒たち：データジャーナリズムと疑念の政治学」に通底する疑問で、ニュースの歴史をより長期的な視点から探ろうとしています。
本書は、1910年代、1960年代、そして現在に立ち戻り、データジャーナリズムの系譜とその物質的・技術的基盤をたどり、報道におけるデータの利用が、国政や計算可能なデータベースの進化、専門科学分野の歴史と不可避的に絡み合っていることを論じている。
社会科学とジャーナリズムの関係を理解しなければ、データのジャーナリズム的利用を理解することは不可能です。
また、実証的に検証可能な情報の出版がより公正で繁栄した世界につながるという非常に根強い進歩的信念を最初に理解しなければ、公の真実を語る実証的な形式を解き明かすことも不可能です。
この本はこのテクノロジーとプロフェッショナリズムの交差が、より良いジャーナリズムをもたらしたが、必ずしもより良い政治をもたらしたわけではないと結論づけています。
デジタル時代の要求を十分に満たすためには、ジャーナリズムは確かさだけでなく経験的な疑念を表現することにも慣れていなければなりません。
皮肉なことに、この「疑いの受容」によって、ジャーナリズムはより科学に近いものになることができるのです。
社会科学への挑戦
「確かさの使徒たち」の物語は、米国の3つの時代に立脚しており、データジャーナリズムの発展について3つの異なる視点を提供しています。
第一は、いわゆる 「進歩の時代」 であり、入手可能な最高の統計によって、国家と一般市民の両方が世界をより公正で人道的な場所にすることができるという信念を伴ったリベラルな政治支配の時代でした。
第二の画期は、1950年代と1960年代で、ジャーナリズム改革者の一部が、ジャーナリズムをより経験的で客観的なものにするための新しいアイデアと方法の源として、定量的社会科学、特に政治学と社会学に目を向け始めた。
彼らは、ますますアクセスしやすくなったデータベースと強力なコンピューターによって、この探求を後押しされました。
第三の画期は2010年代初頭で、データジャーナリズムの最先端が「計算」あるいは「構造化」ジャーナリズムによって補完された時期である。
ビッグデータと「深層機械学習」の現在において、これらのジャーナリストは、ジャーナリズムの客観性は外部参照に依存するのではなく、むしろデータベース自体の構造の中から現れると主張しています。

In each of these periods, data-oriented journalism both responded to but also defined itself in partial opposition to larger currents operating within social science more generally, and this relationship to larger political and social currents helped inform the choice of cases I focused on in this chapter. In other words, I looked for inflection points in journalism history that could help shed light on larger social and political structures, in addition to journalism. In the Progressive Era,1 traditional news reporting largely rejected sociology’s emerging focus on social structures and depersonalized contextual information, preferring to retain their individualistic focus on powerful personalities and important events. As journalism and sociology professionalized, both became increasingly comfortable with making structural claims, but it was not until the 1960s that Philip Meyer and the reformers clustered around the philosophy of Precision Journalism began to hold up quantitative sociology and political science as models for the level of exactitude and context to which journalism ought to aspire. By the turn of the 21st century, a largely normalized model of data journalism began to grapple with doubts about replicability and causality that were increasingly plaguing social science; like social science, it began to experiment to see if “big data” and non-causal forms of correlational behaviouralism could provide insights into social activity.

Apostles of Certainty thus argues implicitly that forms of journalistic expertise and authority are never constructed in isolation or entirely internally to the journalistic field itself. Data journalism did not become data journalism for entirely professional journalistic reasons, nor can this process be analyzed solely through an analysis of journalistic discourse or “self-talk.” Rather, the type of expertise that in the 1960s began to be called data journalism can only be understood relationally, by examining the manner in which data journalists responded to and interacted with their (more authoritative and powerful) social scientific brethren. What’s more, this process cannot be understood solely in terms of the actions and struggles of humans, either in isolation or in groups. Expertise, according to the model I put forward in Apostles of Certainty, is a networked phenomenon in which professional groupings struggle to establish jurisdiction over a wide variety of discursive and material artefacts. Data journalism, to put it simply, would have been impossible without the existence of the database, but the database as mediated through a particular professional understanding of what a database was and how it could be deployed in ways that were properly journalistic (for a more general attempt at this argument about the networked nature of expertise, see Anderson, 2013). It is impossible to understand journalistic authority without also understanding the authority of social science (and the same thing might be said about computer science, anthropology or long-form narrative non-fiction). Journalistic professionalism and knowledge can never be understood solely by looking at the field of journalism itself.

The Persistence of Politics
Data journalism must be understood genealogically and in relation to adjacent expert fields like sociology and political science. All of these fields, in turn, must be analyzed through their larger conceptions of politics and how they come to terms with the fact that the “facts” they uncover are “political” whether they like it or not. Indeed, even the desire for factual knowledge is itself a political act. Throughout the history of data journalism, I argue in Apostles of Certainty, we have witnessed a distinct attempt to lean on the neutrality of social science in order to enact what can only be described as progressive political goals. The larger context in which this connection is forged, however, has shifted dramatically over time. These larger shifts should temper any enthusiasm that what we are witnessing in journalism is a teleological unfolding of journalistic certainty as enabled by increasingly sophisticated digital devices.

In the Progressive Era, proto-data journalists saw the gathering and piling up of quantitative facts as a process of social and political enlightenment, a process that was nonetheless free of any larger political commitments. By collecting granular facts about city sanitation levels, the distribution of poverty across urban spaces, statistics about church attendance and religious practice, labour conditions, and a variety of other bits of factual knowledge—and by transmitting these facts to the public through the medium of the press—social surveyors believed that the social organism would gain a more robust understanding of its own conditions of being. By gaining a better understanding of itself, society would improve, both of its own accord and by spurring politicians towards enacting reformist measures. In this case, factual knowledge about the world spoke for itself; it simply needed to be gathered, visualized and publicized, and enlightenment would follow. We might call this a “naïve and transparent” notion of what facts are—they require no interpretation in and of themselves, and their accumulation will lead to positive social change. Data journalism, at this moment, could be political without explicitly stating its politics.

By the time of Philip Meyer and the 1960s, this easy congruence between transparent facts and politics had been shattered. Journalism was flawed, Meyer and his partisans argued throughout the 1950s and 1960s, because it mistook objectivity for simply collecting a record of what all sides of a political issue might think the truth might be and allowing the reader to make their own decisions about what was true. In an age of social upheaval and political turmoil, journalistic objectivity needed to find a more robust grounding, and it could find its footing on the terrain of objective social science. The starting point for journalistic reporting on an issue should not be the discursive claims of self-interested politicians but rather the cold, hard truth gleaned from an analysis of relevant data with the application of an appropriate method. Such an analysis would be professional but not political; by acting as a highly professionalized cadre of truth-tellers, journalists could cut through the political spin and help plant the public on the terrain of objective truth. The directions this truth might lead, on the other hand, were of no concern. Unlike the earlier generation of blissfully and naively progressive data journalists, the enlightened consequences of data were not a foregone conclusion.

Today I would argue that a new generation of computational journalists has unwittingly reabsorbed some of the political and epistemological beliefs of their Progressive Era forbearers. Epistemologically, there is an increasing belief amongst computational journalists that digital facts in some way “speak for themselves,” or at least these facts will do so when they have been properly collected, sorted and cleaned. At scale, and when linked to larger and internally consistent semantic databases, facts generate a kind of correlational excess in which troubles with meaning or causality are washed away through a flood of computational data. Professionally, data journalists increasingly understand objectivity as emerging from within the structure of the database itself rather than as part of any larger occupational interpretive process. Politically, finally, I would argue that there has been the return of a kind of “crypto-progressivism” amongst many of the most studiously neutral data journalists, with a deep-seated political hope that more and more data, beautifully visualized and conveyed through a powerful press, can act as a break on the more irrational or pathological political tendencies increasingly manifest within Western democracies. Such, at least, was the hope before 2016 and the twin shocks of Brexit and Donald Trump.

Certainty and Doubt
The development of data journalism in the United States across the large arc of the 20th century should be seen as one in which increasingly exact claims to journalistic professional certitude coexisted uneasily with a dawning awareness that all facts, no matter what their origins, were tainted with the grime of politics. These often-contradictory beliefs are evident across a variety of data-oriented fields, of course, not simply just in journalism. In a 2017 article for The Atlantic, for instance, science columnist Ed Yong grappled with how the movement towards “open science” and the growing replicability crisis could be used by an anti-scientific Congress to demean and defund scientific research. Yong quoted Christie Aschwanden, a science reporter at FiveThirtyEight: “It feels like there are two opposite things that the public thinks about science,” she tells Yong.

[Either] it’s a magic wand that turns everything it touches to truth, or that it’s all bullshit because what we used to think has changed. . . . The truth is in between. Science is a process of uncertainty reduction. If you don’t show that uncertainty is part of the process, you allow doubt-makers to take genuine uncertainty and use it to undermine things. (Yong, 2017)

These thoughts align with the work of STS scholar Helga Nowotny (2016), who argues in The Cunning of Uncertainty that “the interplay between overcoming uncertainty and striving for certainty underpins the wish to know.” The essence of modern science—at least in its ideal form—is not the achievement of certainty but rather the fact that it so openly states the provisionality of its knowledge. Nothing in science is set in stone. It admits to often know little. It is through this, the most modern of paradoxes, that its claims to knowledge become worthy of public trust.

One of the insights provided by this genealogical overview of the development and deployment of data journalism, I would argue, is that data-oriented journalists have become obsessed with increasing exactitude and certainty at the expense of a humbler understanding of provisionality and doubt. As I have tried to demonstrate, since the middle of the 20th century journalists have engaged in an increasingly successful effort to render their knowledge claims more certain, contextual and explanatory. In large part, they have done this by utilizing different forms of evidence, particularly evidence of the quantitative sort. Nevertheless, it should be clear that this heightened professionalism—and the increasing confidence of journalists that they are capable of making contextualized truth claims—has not always had the democratic outcomes that journalists expect. Modern American political discourse has tried to come to grips with the uncertainty of modernity by engaging a series of increasingly strident claims to certitude. Professional journalism has not solved this dilemma; rather it has exacerbated it. To better grapple with the complexity of the modern world, I would conclude, journalism ought to rethink the means and mechanisms by which it conveys its own provisionality and uncertainty. If done correctly, this could make journalism more like modern science, rather than less.

Footnotes

1. In the United States the time period known as the “Progressive Era” lasted from the 1880s until the 1920s, and is commonly seen as a great era of liberal reform and an attempt to align public policy with the industrial era.

Works Cited

Anderson, C. W. (2013). Towards a sociology of computational and algorithmic journalism. New Media & Society, 15(7), 1005–1021. doi.org/10.1177/1461444812465137

Anderson, C. W. (2018). Apostles of certainty: Data journalism and the politics of doubt. Oxford University Press.

D’Ignazio, C., & Klein, L. F. (2020). Data feminism. MIT Press.
Foucault, M. (1980). Power/knowledge: Selected interviews and other writings,1972–1977. Vintage.

Nowotny, H. (2016). The cunning of uncertainty. Polity Press.

Yong, E. (2017, April 5). How the GOP could use science’s reform movement against it. The Atlantic. www.theatlantic.com/science/archive/2018/08/scientists-can-collectively-sense-which-psychology-studies-are-weak/568630/

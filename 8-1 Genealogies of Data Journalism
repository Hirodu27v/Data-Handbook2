データジャーナリズムの系譜

Written by: C.W. Anderson
なぜ、データジャーナリズムの歴史に関心を持つべきなのでしょう。
「歴史」は多くの人にとってかなり学術的で抽象的な話題で、仕事に追われる現役のデータ・ジャーナリストにとっては特に縁遠いものかもしれません。
ジャーナリストは、厳しい締め切りの中で、できるだけ多くの読者に複雑な情報を素早く分かりやすく伝えることを目標に仕事をしているので、自省に時間を費やすことを嫌うのは当然でしょう。
しかし、データジャーナリズムやコンピュータ支援報道の実践や概念に関しては、歴史的思考の忌避が、質の高いジャーナリズムの生産を妨げることがあります。
データジャーナリズムは、今日の世界で最も強力なジャーナリズムの集団的センス・メイキングの形態かもしれません。
少なくとも、最もポジティブで実証的なジャーナリズムの形態でしょう。
この力（データジャーナリズムのモデルの修辞的な力とともに、質の高いジャーナリズムを生み出すデータジャーナリズムの能力）、積極性（ほとんどのデータジャーナリストは、自分たちの特定のサブフィールドの将来に大きな期待を持ち、それが上昇傾向にあると確信している）、実証性（データ記者は、世界に関する実際の証明できる事実を捉える、方法に基づいた調査の能力に対する強い信者）により、私が経験的に自信に満ちた職業と呼ぶものが生み出されています。
この自己肯定感の結果、データジャーナリズムは常に世界を改善し、向上させているという（進歩主義的）ホイッグ史観のような思い込みも生まれかねません。
こうした態度は、傲慢さと批判的な自己反省の欠如を招き、ジャーナリズムを、その時間を費やして責任を追及している機関と同じようなものにしてしまう可能性があるのです。
この章では、歴史にもっと注意を向けることで、データ・ジャーナリズムの日々の活動を実際に改善できることを主張したいと思います。
自分たちのプロセスや実践には歴史があることを理解することで、データ・ジャーナリストは、現在の物事がかつてそうでなかったかもしれず、別の方法で行われる可能性があるという事実を受け入れられるのです。
特に、データ・ジャーナリストは、実証的な作業において不確実性を創造的に表現する方法について、より深く考えることができるかもしれません。
また、単に事実上の証拠を述べるだけでなく、さまざまな政治的感性や説得力のある読者を引き込むためのテクニックを考えるかもしれません。
つまり、科学技術研究者で歴史家のキャサリン・ディグナツィオとローレン・クラインが「フェミニスト・データ・ビジュアライゼーション」と呼ぶ、二項対立を再考し、多元性を受け入れ、権力を検証し、文脈を考慮するような形に自らを開放することができるだろう（ディグナツィオとクライン、2020年、本書のディグナツィオの章も参照のこと）。
これらの変化を達成するために、データジャーナリズムは自らの力と自信の性質があるゆえに、ジャーナリズムの実践の多くの形態よりもいっそう確かにこの強力な歴史感覚を教え込むべきである。
私は、ミシェル・フーコーによって開拓され、科学の歴史家や科学技術研究者によって受け入れられた概念の発展への系譜学的アプローチほど、自己再帰性を導く能力を備えた歴史の形式はないと主張したい。
フーコーが定義した「系譜学」は、ニーチェの著作を参考にしながら、制度や概念の時間的変遷を研究するユニークなアプローチであり、歴史とは異なります。
系譜学的分析は、過去の慣習や思想の切れ目のない単一の起源を探すものではないし、概念が昨日から今日まで切れ目のない進化的なラインでどのように発展してきたかを理解しようとするものでもないのです。
むしろ、現在からみて過去がどうだったかということよりも、不連続性や予期せぬ変化に注目します。
ニーチェは、フーコーが引用した『道徳の系譜』の一節で、次のように指摘します。
ある物事、慣習、器官の「発展」は、単一の目標に向かう進歩とは何の関係もなく、ましてや力や資源の最小限の消費で到達する論理的かつ最短の進歩でもない。
むしろそれは、その物に起こる多かれ少なかれ深遠で、多かれ少なかれ相互に独立した圧倒のプロセスの連続であり、その都度その圧倒に対して生じる抵抗、防御と反作用の目的で試みられた形態の変化、および成功した対抗措置の結果なのである。
形は流動的であるが、「意味」はさらに流動的である。(Foucault, 1980)
「データジャーナリズムの系譜」は、データ・ジャーナリズムが、その創作者や実践者が予想しなかった方法で、あるいは彼らの願望に反する方法で進化してきたことを明らかにします。
歴史が私たちを驚かせ、時には予期せぬ方向へ導いてくれるのを目の当たりにしているのです。
このアプローチは、先に述べたように、現代の現役データジャーナリストに特に有効なものです。自分たちは由緒ある伝統の中で働いているのではなく、むしろ、根本的に偶発的な方法で、自分たちの手で作り上げているのだということを理解する助けになると思うのです。
そしてそれは、批判的な自己反省を促すものであり、現役のデータ・ジャーナリストやレポーターの（理解できる、しばしばそれに値する）自負心を和らげるのに役立つかもしれないのです。
私は拙著『確かさの使徒たち：データジャーナリズムと疑念の政治学』で、このような系譜の記述を試みています。
この後のページでは、この本の主な発見をいくつかまとめ、その教訓が現代に役立つかもしれない方法を論じたいと思います。
最後に、ジャーナリズム、特にデータ化された類のジャーナリズムは、知らないことをよりうまく示すことができるし、そうすべきであり、不確実性に向けたこれらのジェスチャーは、データジャーナリズムの起源を、もしそれが表象化されたものであるというよりは、非合法な権力への批判に置くことを尊重するものであると主張したい。
データジャーナリズムの変遷：1910年代、1960年代、2010年代
より良いジャーナリズムを生み出すために、数値の紙文書、データの可視化、チャートやグラフといった他の形式の定量化された情報とともに、データを活用できるか。
そして、そのジャーナリズムは、国民がよりよい政治的選択をするために、どのように役立つのだろうか。
これらの疑問が、「確かさの使徒たち：データジャーナリズムと疑念の政治学」に通底する疑問で、ニュースの歴史をより長期的な視点から探ろうとしています。
本書は、1910年代、1960年代、そして現在に立ち戻り、データジャーナリズムの系譜とその物質的・技術的基盤をたどり、報道におけるデータの利用が、国政や計算可能なデータベースの進化、専門科学分野の歴史と不可避的に絡み合っていることを論じている。
社会科学とジャーナリズムの関係を理解しなければ、データのジャーナリズム的利用を理解することは不可能です。
また、実証的に検証可能な情報の出版がより公正で繁栄した世界につながるという非常に根強い進歩的信念を最初に理解しなければ、公の真実を語る実証的な形式を解き明かすことも不可能です。
この本はこのテクノロジーとプロフェッショナリズムの交差が、より良いジャーナリズムをもたらしたが、必ずしもより良い政治をもたらしたわけではないと結論づけています。
デジタル時代の要求を十分に満たすためには、ジャーナリズムは確かさだけでなく経験的な疑念を表現することにも慣れていなければなりません。
皮肉なことに、この「疑いの受容」によって、ジャーナリズムはより科学に近いものになることができるのです。
社会科学への挑戦
「確かさの使徒たち」の物語は、米国の3つの時代に立脚しており、データジャーナリズムの発展について3つの異なる視点を提供しています。
第一は、いわゆる 「進歩の時代」 であり、入手可能な最高の統計によって、国家と一般市民の両方が世界をより公正で人道的な場所にすることができるという信念を伴ったリベラルな政治支配の時代でした。
第二の画期は、1950年代と1960年代で、ジャーナリズム改革者の一部が、ジャーナリズムをより経験的で客観的なものにするための新しいアイデアと方法の源として、定量的社会科学、特に政治学と社会学に目を向け始めた。
彼らは、ますますアクセスしやすくなったデータベースと強力なコンピューターによって、この探求を後押しされました。
第三の画期は2010年代初頭で、データジャーナリズムの最先端が「計算」あるいは「構造化」ジャーナリズムによって補完された時期である。
ビッグデータと「深層機械学習」の現在において、これらのジャーナリストは、ジャーナリズムの客観性は外部参照に依存するのではなく、むしろデータベース自体の構造の中から現れると主張しています。
これらの時代において、データ指向のジャーナリズムは、社会科学全般の大きな流れに呼応しながらも、それに部分的に対抗する形で自らを定義しており、この大きな政治・社会の流れとの関係が、本章で取り上げる事例の選定に役立ちました。
言い換えれば、私はジャーナリズムの歴史において、ジャーナリズムだけでなく、より大きな社会的・政治的構造に光を当てるのに役立つ変曲点を探ったのです。
進歩主義時代、伝統的なニュース報道は、社会学が新たに注目した社会構造や非人格的な文脈情報をはねつけ、有力な人物や重要な出来事に焦点を当てた個人主義的な報道を維持することを好んでいました。
しかし、フィリップ・マイヤーやプレシジョン・ジャーナリズムの哲学を中心とする改革者たちが1960年代に入って、ジャーナリズムが目指すべき正確さと文脈のレベルのモデルとして、計量社会学と政治学を取り上げ始めました。
21世紀に入ると、データ・ジャーナリズムの標準的モデルは、社会科学をますます悩ませるようになった再現性と因果性への疑念に取り組み始めました。
社会科学のように、「ビッグデータ」と相関的行動主義の非因果的形態が社会活動への洞察を提供できるかどうかを試すようになったのです。
このように、『確かさの使徒たち』は、ジャーナリズムの専門性と権威の形態は、決してジャーナリズムの分野そのものから切り離されて構築されるものではなく、完全に内部的なものでもないことを暗に論じて
データジャーナリズムは、完全に専門的なジャーナリズムの理由からデータ・ジャーナリズムになったわけではないし、このプロセスは、ジャーナリズムの言説や "セルフトーク "の分析のみによって分析できるものでもない。
1960年代にデータ・ジャーナリズムと呼ばれ始めた専門性のタイプは、データ・ジャーナリストが（より権威と力のある）社会科学の同胞に反応し、交流する方法を調べることによってのみ、関係的に理解できるのです。
さらに言えば、このプロセスは、単独であれグループであれ、人間の行動や闘争という観点からだけでは理解できないと思います。
私が『確かさの使徒たち』で提示したモデルによれば、専門知識とは、専門家集団が多種多様な言説的・物質的人工物に対する管轄権を確立しようと争う、ネットワーク化した現象である。
データジャーナリズムは、簡単に言えば、データベースの存在なしには不可能だったわけですが、データベースとは何か、どのようにすればジャーナリズムにふさわしい形で展開できるかという特定の専門家の理解によって媒介されたものです（専門知識のネットワーク化された性質に関するこの議論のより一般的な試みは、Anderson、2013を参照してください）。
社会科学の権威を理解せずにジャーナリズムの権威を理解することは不可能です（コンピュータ科学、人類学、長編物語ノンフィクションについても同じことが言えるかもしれません）。
ジャーナリズムの専門性と知識は、ジャーナリズムという分野そのものを見るだけでは決して理解できないのです。
政治の永続性
データジャーナリズムは、社会学や政治学といった隣接する専門分野との関連において、系譜学的に理解されなければなりません。
そして、これらの分野はすべて、政治に関するより大きな概念を通じて分析され、彼らが発見した「事実」が好むと好まざるとにかかわらず「政治的」であるという事実とどのように折り合いをつけているかが明らかにされなければならないのです。
事実に基づく知識を求めること自体が政治的行為です。
データジャーナリズムの歴史を振り返る『確信の使徒たち』の中で、進歩的な政治目標としか言いようのないものを実現するために、社会科学の中立性に依拠しようとする明確な試みを紹介しました。
しかし、この関係が形成されるより大きな状況は、時間の経過とともに劇的に変化しています。
こうした大きな変化は、ジャーナリズムにおいてわれわれが目撃しているものが、高度化するデジタル機器によって実現されたジャーナリズムの確実性の発展だという、いかなる熱狂をも抑制するはずです

In the Progressive Era, proto-data journalists saw the gathering and piling up of quantitative facts as a process of social and political enlightenment, a process that was nonetheless free of any larger political commitments. By collecting granular facts about city sanitation levels, the distribution of poverty across urban spaces, statistics about church attendance and religious practice, labour conditions, and a variety of other bits of factual knowledge—and by transmitting these facts to the public through the medium of the press—social surveyors believed that the social organism would gain a more robust understanding of its own conditions of being. By gaining a better understanding of itself, society would improve, both of its own accord and by spurring politicians towards enacting reformist measures. In this case, factual knowledge about the world spoke for itself; it simply needed to be gathered, visualized and publicized, and enlightenment would follow. We might call this a “naïve and transparent” notion of what facts are—they require no interpretation in and of themselves, and their accumulation will lead to positive social change. Data journalism, at this moment, could be political without explicitly stating its politics.

By the time of Philip Meyer and the 1960s, this easy congruence between transparent facts and politics had been shattered. Journalism was flawed, Meyer and his partisans argued throughout the 1950s and 1960s, because it mistook objectivity for simply collecting a record of what all sides of a political issue might think the truth might be and allowing the reader to make their own decisions about what was true. In an age of social upheaval and political turmoil, journalistic objectivity needed to find a more robust grounding, and it could find its footing on the terrain of objective social science. The starting point for journalistic reporting on an issue should not be the discursive claims of self-interested politicians but rather the cold, hard truth gleaned from an analysis of relevant data with the application of an appropriate method. Such an analysis would be professional but not political; by acting as a highly professionalized cadre of truth-tellers, journalists could cut through the political spin and help plant the public on the terrain of objective truth. The directions this truth might lead, on the other hand, were of no concern. Unlike the earlier generation of blissfully and naively progressive data journalists, the enlightened consequences of data were not a foregone conclusion.

Today I would argue that a new generation of computational journalists has unwittingly reabsorbed some of the political and epistemological beliefs of their Progressive Era forbearers. Epistemologically, there is an increasing belief amongst computational journalists that digital facts in some way “speak for themselves,” or at least these facts will do so when they have been properly collected, sorted and cleaned. At scale, and when linked to larger and internally consistent semantic databases, facts generate a kind of correlational excess in which troubles with meaning or causality are washed away through a flood of computational data. Professionally, data journalists increasingly understand objectivity as emerging from within the structure of the database itself rather than as part of any larger occupational interpretive process. Politically, finally, I would argue that there has been the return of a kind of “crypto-progressivism” amongst many of the most studiously neutral data journalists, with a deep-seated political hope that more and more data, beautifully visualized and conveyed through a powerful press, can act as a break on the more irrational or pathological political tendencies increasingly manifest within Western democracies. Such, at least, was the hope before 2016 and the twin shocks of Brexit and Donald Trump.

Certainty and Doubt
The development of data journalism in the United States across the large arc of the 20th century should be seen as one in which increasingly exact claims to journalistic professional certitude coexisted uneasily with a dawning awareness that all facts, no matter what their origins, were tainted with the grime of politics. These often-contradictory beliefs are evident across a variety of data-oriented fields, of course, not simply just in journalism. In a 2017 article for The Atlantic, for instance, science columnist Ed Yong grappled with how the movement towards “open science” and the growing replicability crisis could be used by an anti-scientific Congress to demean and defund scientific research. Yong quoted Christie Aschwanden, a science reporter at FiveThirtyEight: “It feels like there are two opposite things that the public thinks about science,” she tells Yong.

[Either] it’s a magic wand that turns everything it touches to truth, or that it’s all bullshit because what we used to think has changed. . . . The truth is in between. Science is a process of uncertainty reduction. If you don’t show that uncertainty is part of the process, you allow doubt-makers to take genuine uncertainty and use it to undermine things. (Yong, 2017)

These thoughts align with the work of STS scholar Helga Nowotny (2016), who argues in The Cunning of Uncertainty that “the interplay between overcoming uncertainty and striving for certainty underpins the wish to know.” The essence of modern science—at least in its ideal form—is not the achievement of certainty but rather the fact that it so openly states the provisionality of its knowledge. Nothing in science is set in stone. It admits to often know little. It is through this, the most modern of paradoxes, that its claims to knowledge become worthy of public trust.

One of the insights provided by this genealogical overview of the development and deployment of data journalism, I would argue, is that data-oriented journalists have become obsessed with increasing exactitude and certainty at the expense of a humbler understanding of provisionality and doubt. As I have tried to demonstrate, since the middle of the 20th century journalists have engaged in an increasingly successful effort to render their knowledge claims more certain, contextual and explanatory. In large part, they have done this by utilizing different forms of evidence, particularly evidence of the quantitative sort. Nevertheless, it should be clear that this heightened professionalism—and the increasing confidence of journalists that they are capable of making contextualized truth claims—has not always had the democratic outcomes that journalists expect. Modern American political discourse has tried to come to grips with the uncertainty of modernity by engaging a series of increasingly strident claims to certitude. Professional journalism has not solved this dilemma; rather it has exacerbated it. To better grapple with the complexity of the modern world, I would conclude, journalism ought to rethink the means and mechanisms by which it conveys its own provisionality and uncertainty. If done correctly, this could make journalism more like modern science, rather than less.

Footnotes

1. In the United States the time period known as the “Progressive Era” lasted from the 1880s until the 1920s, and is commonly seen as a great era of liberal reform and an attempt to align public policy with the industrial era.

Works Cited

Anderson, C. W. (2013). Towards a sociology of computational and algorithmic journalism. New Media & Society, 15(7), 1005–1021. doi.org/10.1177/1461444812465137

Anderson, C. W. (2018). Apostles of certainty: Data journalism and the politics of doubt. Oxford University Press.

D’Ignazio, C., & Klein, L. F. (2020). Data feminism. MIT Press.
Foucault, M. (1980). Power/knowledge: Selected interviews and other writings,1972–1977. Vintage.

Nowotny, H. (2016). The cunning of uncertainty. Polity Press.

Yong, E. (2017, April 5). How the GOP could use science’s reform movement against it. The Atlantic. www.theatlantic.com/science/archive/2018/08/scientists-can-collectively-sense-which-psychology-studies-are-weak/568630/

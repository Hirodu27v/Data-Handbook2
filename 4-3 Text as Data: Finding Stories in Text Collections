データとしてのテキスト：テキスト収集からストーリーを見つける



Written by Barbara Maseda

概要

文書やスピーチのコレクションからデータストーリーを見つける方法

キーワード：データ・ジャーナリズム、非構造化データ、テキスト分析、テキストマイニング、計算報道学

ここ数年のデータ・ジャーナリズムの制作状況を見ると、非構造化データ（テキストなど）をベースにしたストーリーは、構造化データをベースにしたストーリーに比べてはるかに少ないことに気づくかもしれません。

例えば、2012～16年にデータ・ジャーナリズム・アワードにノミネートされた200件以上の作品を分析したところ、応募作品は主に地理的データと金融データに依存しており、次いでセンサー、社会・人口統計、個人データ、メタデータ、投票など頻繁に使用されるタイプのソースであることがわかりました（Loosen et al, 2020）。
つまりほとんどが構造化データです。
しかし、ニュースルームでは、ソーシャルメディアへの投稿、スピーチ、電子メール、長文の公式報告書などを扱う機会が増えており、これらのソースを処理・分析するための計算論的アプローチが重要になっています。
あなたもこの方法で作られた物語を目にしたことがあるかもしれません。例えば、トランプ大統領のツイートを統計的にまとめたものや、アメリカの選挙で大統領候補者が公の場や討論会で取り上げた主なトピックを可視化したものなどがあります。
テキストをデータとして扱うことは簡単なことではありません。ドキュメントは、フォーマット、レイアウト、内容が最も多様である傾向があるため、画一的なソリューションや、ある調査を別のドキュメントセットで再現しようとすると、複雑になります。
データのクリーニング、準備、分析は、文書のコレクションごとに大きく異なります。また、報道する価値のある主張をしたり、研究者だけでなく広く一般の人々にとっても意味のある調査結果を発表する前に、さらに人の目で確認しなければならないステップもあります。
本章では、ジャーナリストがストーリーを伝えるためにテキスト分析を利用する五つの方法を、データ・ジャーナリズムのさまざまな模範的プロジェクトを参照しながら検討します。


長さ：どれだけ書いたか、語ったか
文章や単語を数えることは、文書に対する最も単純な定量的アプローチです。昔からある作業で、ほとんどのワープロで簡単に実行できます。
学生や記者の方で、字数制限のある課題を提出したことがある方なら、特別なデータトレーニングを受けなくても理解できるでしょう。
単語数の問題点は、意味のあるベースラインに照らし合わせて結果を解釈することです。このような尺度は、温度や速度のように広く知られているわけではないので、スピーチが2,000語であるという事実から意味を導き出すのは、それほど簡単ではないかもしれません。
実際には、比較のためのベースラインやリファレンスを自分たちで作成するしかない場合が多く、それがさらなる作業につながることもあります。
場合によっては、調べようとしているイベントやスピーカーの歴史に文脈を見出すことも可能です。
例えば、2016年に行われたアメリカ大統領の年次一般教書演説の報道では、Voxは全ての歴史的な演説の長さを計算して、「オバマ大統領は史上最も言葉数の多い一般教書演説者の一人である」と判断しました（Chang, 2016）。
複数の人が話すイベントでは、それぞれの人が話す量やタイミングを、話した言葉の総数との関係で調べることができます。図17.1をご覧ください。


Figure 17.1
Figure 17.1. Visualisation of the Democratic Party debate (2015). Source: The Washington Post, https://www.washingtonpost.com/graphics/politics/2016-election/debates/oct-13-speakers/
Mentions: Who Said What, When and How Many Times
ある用語や概念が会話や文章の中で何回使われたかを数えることも、データの統計的な概要を把握するための簡単な作業です。そのためには、最も適切な要素を選択してカウントすることが重要です。
データから探ろうとする課題に応じ、"ステミング"や "レンマ化"などの正規化操作を使用して、各単語の繰り返しを数えたり、共通の語幹を持つ単語の繰り返しを数えたりすることができます。
また、"term frequency/inverse document frequency" (TF-IDF) と呼ばれる重み付けされた尺度を用いて、各文書の中で最も関連性の高い用語に焦点を当てるというアプローチもあります。次のような例があります。
頻出する用語やトピック。ガーディアンは、2016年のロンドン市長選挙で、2人の候補者が選挙前の6年間に英国議会で様々な争点となる問題（犯罪、汚染、住宅、交通など）を取り上げた回数を分析しました（Barr, 2016）。
分析対象となるトピックは、今回のようにあらかじめ決めておき、比較可能なテキストコレクションや類似のテキストコレクションに含まれる多数の関連キーワード（またはトピックに関連するキーワード群）から探索することができます。
た、検索語は類似していても、必ずしも同じではありません。例えば、同じメディアが2017年に発生した3つの異なるハリケーン（ハービー、イルマ、マリア）をどのように報道したかというFiveThirtyEightの分析を見てみましょう（Mehta, 2017）。
もう一つのアプローチは、トピック検出戦略として単にテキスト内の最も一般的な単語に注目することです。
スピーチの経時的分析。スピーチを時系列で見ることは、これまで言及されなかった、あるいは長い間取り上げられていなかったトピックを指摘する方法でもあります。
例えば、ワシントン・ポスト紙が2018年の一般教書演説を報道する際に選択したアプローチは、どの大統領がどの言葉を最初に使ったかを強調した記事でした（Fischer-Baum et al.2018）。
読者は、何百ページもの演説を読まなくても、トランプがウォルマート（2017年）やただ乗り（2019年）に言及した史上初の大統領であることを非常に素早く知ることができ、テキストデータの要約と可視化がいかに効果的であるかを示している。
省略。言及の数が少なかったり、全く言及がなかったりすることも、ニュースになることがあります。このような言及漏れは、時系列で分析できますが、加えて人や組織がある文脈で何かに言及するという期待に基づいて分析することもできます。
2016年の米大統領選挙期間中、FiveThirtyEightは、ドナルド・トランプ候補のツイートに世論調査に関するキーワードの言及が比較的少ないことを発見し、世論調査に関するツイートをやめたと報じました（Mehta & Enten, 2016）。
このような省略は、同じ発言者を長期的に監視することで発見することができます。今回のケースでは、FiveThirtyEightは数ヶ月前から、トランプが自分が勝っているように見せている世論調査をたくさんツイートしていることを発見していました（Bialik & Enten, 2015）。
これは、上述したテキスト統計の文脈化の問題を解決する方法として、テキスト分析に基づいたニュースレポートが、後にフォローアップ記事の文脈となることを示す良い例でもあります。
あるトピックの不在は、人や組織がある文脈でそのトピックについて言及するという期待に基づいて測定することもできるのです。
人、場所、名詞、動詞。自然言語処理 (NLP) ツールは、(固有表現抽出 (NER) と呼ばれるタスクを介して)固有名詞や地名、企業名などの要素の抽出 、(品詞タグ付け (POS) と呼ばれるタスクを介して) 名詞や形容詞などの単語の識別を可能にします。
先ほどのワシントン・ポストの記事では、ビジュアライゼーションに企業や宗教用語、動詞などに焦点を当てたフィルタリングが含まれています。

比較
複数の文書がどれだけ類似しているかを判断することが、さまざまな種類のストーリーの出発点になります。
近似文マッチング（「ファジー・マッチング」とも呼ばれる）を利用して、盗作を暴いたり、公人の交友関係を明らかにしたり、ある法案がどのように変更されたかを説明したりすることができます。
2012年、プロパブリカは、選挙運動によって有権者に送られた電子メールの変化を追跡するために、同じメッセージの連続したバージョンを並べて表示し、削除、挿入、および変更されていないテキストを可視化しました（Larson & Shaw, 2012）。


分類
テキストは、機械学習アルゴリズムを用いて、あらかじめ定義された特定の特徴に応じてカテゴリーに分類することができます。
このプロセスは一般に、与えられた特徴に基づいてエントリーを分類するモデルを学習し、それを新しいデータの分類に使用する構成となっています。
例えば、ロサンゼルス・タイムズ紙は2015年、公的記録請求で入手した40万件以上の警察報告書を分析し、市警が推定1万4,000件の重大な暴行を軽犯罪に誤分類していたことを明らかにしました (Poston et al., 2015)。
記者は、データ量の少ない以前の調査で行ったように、MySQLを使って凶悪犯罪を示すキーワード（刺す、ナイフなど）を検索するのではなく、機械学習の分類器（SVMとMaxEnt）を使って8年分のデータを再分類し、1年のみを対象とした最初の調査の半分の時間で検証しました（Poston & Rubin, 2014）。
この例は、機械学習アプローチが時間を節約し、調査力を倍増させることもできることを示しています。

感触
多くのジャーナリストは、問題となっているテーマに対する発言者の態度に応じて、文章や文書をポジティブ、ネガティブ、ニュートラル（他の評価尺度も可能）に分類することの価値を認識しています。
の応用例としては、トピック、ハッシュタグ、Twitterユーザーの投稿などを分析して問題に対するセンチメントを評価したり、プレスリリースやウェブサイト上のユーザーのコメントに対して同様の計算を行ったりすることが挙げられます。
例えば、エコノミスト誌がヒラリー・クリントンとドナルド・トランプの党大会でのスピーチのトーンを比較しています（「How Clinton's and Trump's Convention Speeches," 2016」）。
これらの候補者と過去の候補者が使用した言葉の極性を分析し、トランプは「最近の記憶の中で最もネガティブなスピーチをした」、クリントンは「過去40年間で最も平静なスピーチの一つ」であることを示すことができたのです。

テキスト・マイナー・ジャーナリストを目指して
市販のテキストマイニングソフトウェアを使用すれば、基本的なテキスト分析操作とその結果（単語数、エンティティ抽出、文書間のつながりなど）にスムーズに慣れることができます。
DocumentCloudやOverviewなど、ジャーナリスト向けに設計されたプラットフォームには、これらの機能の一部が含まれています。
Google Cloud Natural Language APIは、センチメント分析、エンティティ分析、コンテンツ分類、構文分析など、さまざまなタスクを処理することができます。
テキストマイニングについて詳しく知りたい方には、Python（NLTK、spaCy、gensim、textblob、scikit-learn）やR（tm、tidytextなど）のリソースを含む、よりパーソナライズされた分析を可能にする無料のオープンソースツールがありますが、すでにこれらの言語に慣れ親しんでいるジャーナリストにとっては、その方が便利かもしれません。
また、正規表現や、テキストの収集（ウェブスクレイピング、APIクエリ、情報公開請求）や処理（光学式文字認識（OCR）、ファイル形式の変換など）に必要なツールやテクニックを使いこなせることも必要です。
そしてもちろん、情報検索、関連モデルやアルゴリズム、テキストデータの可視化など、テキストデータ作業の背景にある理論や原理を把握することも有効です。
結論
文書に関する新たな洞察を読者に提供できる可能性や、読むのに何ヶ月も何年もかかるような長いテキストを分析する能力を高めることができることは、ジャーナリズムの有用なツールとしてテキスト分析の開発を真剣に検討する十分な理由となります。
曖昧さの問題（コンピュータは人間よりも言語の文脈を「理解」するのが難しいかもしれない）から、言語特有の問題（ドイツ語よりも英語の方が解決しやすい場合がある）、ある言語では他の言語よりも多く取り組まれてきた問題まで、課題はまだまだたくさんあります。
ジャーナリストとしての私たちの仕事は、この分野の発展に貢献することができます。多くの報道プロジェクトは、利用可能な注釈付きデータセットの数を増やし、課題を特定し、新しいアプリケーションのアイデアを生み出すとも言えます。
このアプローチで制作された最近の記事の数が増えていることから判断すると、テキストマイニングはデータジャーナリズムの中でも有望でエキサイティングな成長分野なのです。

Footnotes

1. For more on the Data Journalism Awards, see Loosen’s chapter in this volume.

2. Data cleaning and preparation may include one or more of the following steps: Breaking down the text into units or tokens (a process known as “tokenization”); “grouping” words that share a common family or root (stemming and lemmatization); eliminating superfluous elements, such as stopwords and punctuation; changing the case of the text; choosing to focus on the words and ignore their order (a model called “bag of words”); and transforming the text into a vector representation.

3. Stemming and lemmatization are operations to reduce derived words to their root form, so that occurrences of “reporter,” “reporting” and “reported” can all be counted under the umbrella of “report.” They differ in the way that the algorithm determines the root of the word. Unlike lemattizers, stemmers strip words of their suffixes without taking into consideration what part of speech they are.

4. TF-IDF is a measure used by algorithms to understand the weight of a word in a collection. TF-IDF Weight (w, d) = TermFreq(w, d) · log (N / DocFreq(w)), where TermFreq(w, d) is the frequency of the word in the document (d), N is the number of all documents and DocFreq(w) is the number of documents containing the word w (Feldman and Sanger, 2007).

5. www.documentcloud.org, www.overviewdocs.com

6. cloud.google.com/natural-language

7. regex.bastardsbook.com

8. For further reading, see Speech and Language Processing by Daniel Jurafsky and James H. Martin; The Text Mining Handbook by Ronen Feldman and James Sanger. There are also numerous free online courses on these and associated topics.

Works cited

Barr, C. (2016, May 3). London mayor: Commons speeches reveal candidates’ differing issue focus. The Guardian. www.theguardian.com/politics/datablog/2016/may/03/london-mayor-data-indicates-candidates-differing-focus-on-issues

Bialik, C., & Enten, H. (2015, December 15). Shocker: Trump tweets the polls that make him look most like a winner. FiveThirtyEight. fivethirtyeight.com/features/shocker-trump-tweets-the-polls-that-make-him-look-most-like-a-winner/

Chang, A. (2016, January 11). President Obama is among the wordiest State of the Union speakers ever. Vox. www.vox.com/2016/1/11/10736570/obama-wordy-state-of-the-union

Feldman, R., & Sanger, J. (2007). The text mining handbook: Advanced approaches in analyzing unstructured data. Cambridge University Press.

Fischer-Baum, R., Mellnik, T., & Schaul, K. (2018, January 30). The words Trump used in his State of the Union that had never been used before. The Washington Post. www.washingtonpost.com/graphics/politics/presidential-lexicon-state-of-the-union/

How Clinton’s and Trump’s convention speeches compared to those of their predecessors. (2016, July 29). The Economist. www.economist.com/graphic-detail/2016/07/29/how-clintons-and-trumps-convention-speeches-compared-to-those-of-their-predecessors

Jurafsky, D., & Martin, J. H. (2008). Speech and Language Processing. Pearson.

Larson, J., & Shaw, A. (2012, July 17). Message machine: Reverse engineering the 2012 campaign. ProPublica. projects.propublica.org/emails/

Loosen, W., Reimer, J., & De Silva-Schmidt, F. (2020). Data-driven reporting: An on-going (r)evolution? An analysis of projects nominated for the Data Journalism Awards 2013–2016. Journalism, 21(9), 1246–1263. https://doi. org/10.1177/1464884917735691

Mehta, D. (2017, September 28). The media really has neglected Puerto Rico. FiveThirtyEight. fivethirtyeight.com/features/the-media-really-has-neglected-puerto-rico/

Mehta, D., & Enten, Ha. (2016, August 19). Trump isn’t tweeting about the polls anymore. FiveThirtyEight. fivethirtyeight.com/features/trump-isnt-tweeting-about-the-polls-anymore/

Poston, B., & Rubin, J. (2014, August 10). Times Investigation: LAPD misclassified nearly 1,200 violent crimes as minor offenses. Los Angeles Times. www.latimes.com/local/la-me-crimestats-lapd-20140810-story.html

Poston, B., Rubin, J., & Pesce, A. (2015, October 15). LAPD underreported serious assaults, skewing crime stats for 8 years. Los Angeles Times. www.latimes.com/local/cityhall/la-me-crime-stats-20151015-story.html
